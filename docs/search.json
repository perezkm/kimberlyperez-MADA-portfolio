[
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About Me",
    "section": "",
    "text": "Hello! My name is Kimberly Perez and I am a first year PhD student in Environmental Health Science under the advisement of Dr. Erin Lipp. My current research focuses on Salmonella in wildlife. While most folks associate Salmonella with raw poultry or even peanut butter, a rising subset of cases is actually linked to environmental factors. From my one semester as a PhD student (and my research so far) I offer everyone two pieces of advise don’t kiss your chickens and wash your hands after handling bird feeders…"
  },
  {
    "objectID": "aboutme.html#course-goals",
    "href": "aboutme.html#course-goals",
    "title": "About Me",
    "section": "Course Goals",
    "text": "Course Goals\nMy first introduction to programming was during the first semester of my MPH. My class learned how to run a few lines of code using STATA. I also learned some basic functions on SAS. However, the bulk of my experience comes from Dr. Bahl’s EPID 7500 class. That was my first true introduction to R. While that semester was a whirlwind of Googling, I was happy with the content I created.\nFrom this course I hope to gain a greater understanding of the R language and the packages that will help me analyze my data, appropriate statistical models to run based on specific data, and how to better interpret results."
  },
  {
    "objectID": "aboutme.html#fun-fact",
    "href": "aboutme.html#fun-fact",
    "title": "About Me",
    "section": "Fun Fact",
    "text": "Fun Fact\nI am a licensed USSF soccer coach and would one day like to pursue my “Pro” license."
  },
  {
    "objectID": "aboutme.html#not-so-standard-deviations-podcast",
    "href": "aboutme.html#not-so-standard-deviations-podcast",
    "title": "About Me",
    "section": "Not So Standard Deviations Podcast",
    "text": "Not So Standard Deviations Podcast\nI am a big podcast fan and try to find new ones to listen to while I do my lab work. Not So Standard Deviations is my latest find. The hosts Roger and Hilary discuss all things data science and analysis. Besides this, I cannot provide much more insight as I am only a couple episodes in. However, I am pretty intrigued so far and think this will be my go to podcast this semester. Enjoy!"
  },
  {
    "objectID": "coding_exercise.html",
    "href": "coding_exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "This is the beginning of the loading and checking data exercise where I will install, load, and explore the dslabs package!\n\n\nNOTE: Use library() to list all of the packages installed on my system\n\n\nInstalling packages\ninstall.packages(“dslabs”)\ninstall.packages(“dplyr”)\n\n\nLoading packages\n\nlibrary (\"dplyr\") \n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(\"dslabs\")\nlibrary(ggplot2) \n\n\n\nWhat Does the gapminder Dataset Contain?\n\nLook at help file to see what the dataset gapminder contains help(gapminder). Gapminder includes health and income outcomes for 184 countries from 1960 to 2016.\n\nhelp(gapminder)\n\nstarting httpd help server ... done\n\n\n\n\n\nOverview of data structure\n\nstr(gapminder)\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\n\n\n\nSummary of data\n\nsummary(gapminder)\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586  \n\n\n\n\nDetermining the type of object gapminder is via class()\n\nclass(gapminder)\n\n[1] \"data.frame\"\n\n\n\n\nAssigning\n\nI want to create an object (or dataframe) called africadata using an existing dataframe, gapminder, then subset gapminder dataframe using the continent column calling Africa (character string to find)\n\nafricadata<- gapminder %>% subset(continent==\"Africa\")\n\nstr(africadata)\n\n'data.frame':   2907 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n $ fertility       : num  7.65 7.32 6.28 6.62 6.29 6.95 5.65 6.89 5.84 6.25 ...\n $ population      : num  11124892 5270844 2431620 524029 4829291 ...\n $ gdp             : num  1.38e+10 NA 6.22e+08 1.24e+08 5.97e+08 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\nsummary (africadata)\n\n         country          year      infant_mortality life_expectancy\n Algeria     :  57   Min.   :1960   Min.   : 11.40   Min.   :13.20  \n Angola      :  57   1st Qu.:1974   1st Qu.: 62.20   1st Qu.:48.23  \n Benin       :  57   Median :1988   Median : 93.40   Median :53.98  \n Botswana    :  57   Mean   :1988   Mean   : 95.12   Mean   :54.38  \n Burkina Faso:  57   3rd Qu.:2002   3rd Qu.:124.70   3rd Qu.:60.10  \n Burundi     :  57   Max.   :2016   Max.   :237.40   Max.   :77.60  \n (Other)     :2565                  NA's   :226                     \n   fertility       population             gdp               continent   \n Min.   :1.500   Min.   :    41538   Min.   :4.659e+07   Africa  :2907  \n 1st Qu.:5.160   1st Qu.:  1605232   1st Qu.:8.373e+08   Americas:   0  \n Median :6.160   Median :  5570982   Median :2.448e+09   Asia    :   0  \n Mean   :5.851   Mean   : 12235961   Mean   :9.346e+09   Europe  :   0  \n 3rd Qu.:6.860   3rd Qu.: 13888152   3rd Qu.:6.552e+09   Oceania :   0  \n Max.   :8.450   Max.   :182201962   Max.   :1.935e+11                  \n NA's   :51      NA's   :51          NA's   :637                        \n                       region   \n Eastern Africa           :912  \n Western Africa           :912  \n Middle Africa            :456  \n Northern Africa          :342  \n Southern Africa          :285  \n Australia and New Zealand:  0  \n (Other)                  :  0  \n\n\n\n\n\nCreating new objects\n\nI want to create an object (df) called imle using an existing df, africadata, then select 2 columns LE and IM\n\nimle<-africadata %>% select(c(\"life_expectancy\", \"infant_mortality\"))\n\nple<- africadata %>% select(c(\"life_expectancy\", \"population\"))\n\nstr(imle) \n\n'data.frame':   2907 obs. of  2 variables:\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n $ infant_mortality: num  148 208 187 116 161 ...\n\nsummary(imle)\n\n life_expectancy infant_mortality\n Min.   :13.20   Min.   : 11.40  \n 1st Qu.:48.23   1st Qu.: 62.20  \n Median :53.98   Median : 93.40  \n Mean   :54.38   Mean   : 95.12  \n 3rd Qu.:60.10   3rd Qu.:124.70  \n Max.   :77.60   Max.   :237.40  \n                 NA's   :226     \n\nstr(ple) \n\n'data.frame':   2907 obs. of  2 variables:\n $ life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n $ population     : num  11124892 5270844 2431620 524029 4829291 ...\n\nsummary(ple)\n\n life_expectancy   population       \n Min.   :13.20   Min.   :    41538  \n 1st Qu.:48.23   1st Qu.:  1605232  \n Median :53.98   Median :  5570982  \n Mean   :54.38   Mean   : 12235961  \n 3rd Qu.:60.10   3rd Qu.: 13888152  \n Max.   :77.60   Max.   :182201962  \n                 NA's   :51         \n\n\n\n\n\nPlotting\n\nplot_1<- plot(life_expectancy~infant_mortality, data=imle, main=\"Exercise: Plot 1\", ylab= \"Life Expectancy\", xlab=\"Infant Mortality\")\n\n\n\nplot_2<- plot(life_expectancy~population, data=ple, main=\"Exercise: Plot 2\", ylab= \"Life Expectancy\", xlab=\"Population\", log='x')\n\n\n\n\n\n\nQuestion on data\n\nBased on the africadata we generated the “clusters” or “streaks” of data seem to be a population in the the same region of Africa over time. Public health strategies that were implemented (e.g., vaccines, clean water, etc.) may have contributed to the increase in life expectancy and a growing population.\n\n\n\nMore Data Processing\n\nimna<-africadata[is.na(africadata$infant_mortality),]\nunique(imna$year)\n\n [1] 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974\n[16] 1975 1976 1977 1978 1979 1980 1981 2016\n\ny2k<- africadata[which(africadata$year==\"2000\"),]\nstr(y2k)\n\n'data.frame':   51 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ infant_mortality: num  33.9 128.3 89.3 52.4 96.2 ...\n $ life_expectancy : num  73.3 52.3 57.2 47.6 52.6 46.7 54.3 68.4 45.3 51.5 ...\n $ fertility       : num  2.51 6.84 5.98 3.41 6.59 7.06 5.62 3.7 5.45 7.35 ...\n $ population      : num  31183658 15058638 6949366 1736579 11607944 ...\n $ gdp             : num  5.48e+10 9.13e+09 2.25e+09 5.63e+09 2.61e+09 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\nsummary(y2k)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0  \n\n\n\n\nMore Plotting\n\nplot_1<- plot(life_expectancy~infant_mortality, data=y2k, main=\"Africa's LE and IM for the Year 2000\", ylab= \"Life Expectancy\", xlab=\"Infant Mortality\")\n\n\n\nplot_y2k2<- plot(life_expectancy~population, data=y2k, main=\"Africa's LE and Population for the Year 2000\", ylab= \"Life Expectancy\", xlab=\"Population\", log='x')\n\n\n\n\n\n\nA Simple Fit\n\nfit1<-lm(life_expectancy~infant_mortality, data=y2k)\nsummary(fit1)\n\n\nCall:\nlm(formula = life_expectancy ~ infant_mortality, data = y2k)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.6651  -3.7087   0.9914   4.0408   8.6817 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      71.29331    2.42611  29.386  < 2e-16 ***\ninfant_mortality -0.18916    0.02869  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.221 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\n\nfit2<-lm(life_expectancy~population, data=y2k)\nsummary(fit2)\n\n\nCall:\nlm(formula = life_expectancy ~ population, data = y2k)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.429  -4.602  -2.568   3.800  18.802 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 5.593e+01  1.468e+00  38.097   <2e-16 ***\npopulation  2.756e-08  5.459e-08   0.505    0.616    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.524 on 49 degrees of freedom\nMultiple R-squared:  0.005176,  Adjusted R-squared:  -0.01513 \nF-statistic: 0.2549 on 1 and 49 DF,  p-value: 0.6159\n\n\n\n\nWhat do the p-values tell us?\n\nBased on the p-values for the given fits, IM as a predictor of LE is said to be statistically significant whereas population as a predictor of LE is said to not statistically significant. But p-values?…\n\n\n\nSection by Leah Lariscy\n\nI want to see how LE differs between regions in Africa in 2000. I am going to create a boxplot using y2k with region on the x-axis and life_expectancy on the y-axis\n\nggplot(data = y2k) + geom_boxplot(aes(region, life_expectancy))\n\n\n\n\n\n\nFrom the plot above, I can tell the life expectancy is significantly higher in Northern Africa than in the rest of the continent. Now I am going to plot region vs gdp to see if there is a similar trend happening\n\nggplot(data = y2k) + geom_boxplot(aes(region, gdp))\n\n\n\n\n\n\nLooking at both of these plots, I am hypothesizing that gdp and life expectancy have a positive correlation aka that gdp is a good predictor for life expectancy. I am now going to plot log10(gdp) vs LE and use lm.\n\nggplot(data = y2k, aes(log10(gdp), life_expectancy)) + geom_point() + geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\ny2k_lm <- lm(formula = log10(gdp)~life_expectancy, data = y2k)\nsummary(y2k_lm)\n\n\nCall:\nlm(formula = log10(gdp) ~ life_expectancy, data = y2k)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38394 -0.31214  0.00911  0.46180  1.58235 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      8.07684    0.59019  13.685   <2e-16 ***\nlife_expectancy  0.02596    0.01036   2.507   0.0156 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6196 on 49 degrees of freedom\nMultiple R-squared:  0.1137,    Adjusted R-squared:  0.09556 \nF-statistic: 6.283 on 1 and 49 DF,  p-value: 0.01556\n\n\n\n\nThere is some correlation between gdp and LE across Africa in 2000, but not a strong enough correlation for me to think it is significant.\n\n\n\n——————————————–\n\n\nThis section added by RAQUEL FRANCISCO\n\nInstall need packages needed and open library\n\n#install.packages('broom')\n#install.packages(\"tidymodels\")\nlibrary(broom)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n\n✔ dials        1.1.0     ✔ tibble       3.1.8\n✔ infer        1.0.4     ✔ tidyr        1.3.0\n✔ modeldata    1.1.0     ✔ tune         1.0.1\n✔ parsnip      1.0.3     ✔ workflows    1.1.2\n✔ purrr        1.0.1     ✔ workflowsets 1.0.0\n✔ recipes      1.0.4     ✔ yardstick    1.1.0\n✔ rsample      1.1.1     \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\n\n\n\nUse broom package to look at stats differently\n\n\nLife Exp Vs Infant Mortality\n\naugment(fit1)\n\n# A tibble: 51 × 9\n   .rownames life_expect…¹ infan…² .fitted  .resid   .hat .sigma .cooksd .std.…³\n   <chr>             <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>   <dbl>\n 1 7402               73.3    33.9    64.9   8.42  0.0627   6.16 6.54e-2  1.40  \n 2 7403               52.3   128.     47.0   5.28  0.0714   6.24 2.98e-2  0.880 \n 3 7418               57.2    89.3    54.4   2.80  0.0219   6.27 2.32e-3  0.455 \n 4 7422               47.6    52.4    61.4 -13.8   0.0346   5.95 9.10e-2 -2.25  \n 5 7426               52.6    96.2    53.1  -0.496 0.0260   6.28 8.69e-5 -0.0807\n 6 7427               46.7    93.4    53.6  -6.93  0.0241   6.20 1.57e-2 -1.13  \n 7 7429               54.3    91.9    53.9   0.391 0.0232   6.29 4.80e-5  0.0636\n 8 7431               68.4    29.1    65.8   2.61  0.0724   6.27 7.41e-3  0.436 \n 9 7432               45.3   114.     49.8  -4.50  0.0452   6.25 1.30e-2 -0.741 \n10 7433               51.5   106.     51.3   0.201 0.0348   6.29 1.96e-5  0.0329\n# … with 41 more rows, and abbreviated variable names ¹​life_expectancy,\n#   ²​infant_mortality, ³​.std.resid\n\nglance(fit1)\n\n# A tibble: 1 × 12\n  r.squ…¹ adj.r…² sigma stati…³ p.value    df logLik   AIC   BIC devia…⁴ df.re…⁵\n    <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>   <int>\n1   0.470   0.459  6.22    43.5 2.83e-8     1  -165.  335.  341.   1896.      49\n# … with 1 more variable: nobs <int>, and abbreviated variable names\n#   ¹​r.squared, ²​adj.r.squared, ³​statistic, ⁴​deviance, ⁵​df.residual\n\ntidy(fit1)\n\n# A tibble: 2 × 5\n  term             estimate std.error statistic  p.value\n  <chr>               <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)        71.3      2.43       29.4  8.91e-33\n2 infant_mortality   -0.189    0.0287     -6.59 2.83e- 8\n\n\n\nPlot by region\n\nggplot(y2k, aes(life_expectancy,       infant_mortality, color=region)) + geom_point() + stat_smooth(method = \"lm\", col = \"green\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nLife Exp Vs Population\n\naugment(fit2)\n\n# A tibble: 51 × 9\n   .rownames life_expecta…¹ popul…² .fitted .resid   .hat .sigma .cooksd .std.…³\n   <chr>              <dbl>   <dbl>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl>\n 1 7402                73.3  3.12e7    56.8  16.5  0.0295   8.27 5.87e-2   1.97 \n 2 7403                52.3  1.51e7    56.3  -4.05 0.0196   8.59 2.30e-3  -0.479\n 3 7418                57.2  6.95e6    56.1   1.08 0.0227   8.61 1.90e-4   0.128\n 4 7422                47.6  1.74e6    56.0  -8.38 0.0276   8.52 1.41e-2  -0.997\n 5 7426                52.6  1.16e7    56.3  -3.65 0.0203   8.60 1.94e-3  -0.433\n 6 7427                46.7  6.77e6    56.1  -9.42 0.0229   8.50 1.46e-2  -1.12 \n 7 7429                54.3  1.59e7    56.4  -2.07 0.0196   8.61 6.02e-4  -0.245\n 8 7431                68.4  4.39e5    55.9  12.5  0.0291   8.42 3.30e-2   1.48 \n 9 7432                45.3  3.73e6    56.0 -10.7  0.0254   8.47 2.12e-2  -1.28 \n10 7433                51.5  8.34e6    56.2  -4.66 0.0218   8.59 3.41e-3  -0.553\n# … with 41 more rows, and abbreviated variable names ¹​life_expectancy,\n#   ²​population, ³​.std.resid\n\nglance(fit2)\n\n# A tibble: 1 × 12\n  r.squ…¹ adj.r…² sigma stati…³ p.value    df logLik   AIC   BIC devia…⁴ df.re…⁵\n    <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>   <int>\n1 0.00518 -0.0151  8.52   0.255   0.616     1  -181.  367.  373.   3560.      49\n# … with 1 more variable: nobs <int>, and abbreviated variable names\n#   ¹​r.squared, ²​adj.r.squared, ³​statistic, ⁴​deviance, ⁵​df.residual\n\ntidy(fit2)\n\n# A tibble: 2 × 5\n  term             estimate    std.error statistic  p.value\n  <chr>               <dbl>        <dbl>     <dbl>    <dbl>\n1 (Intercept) 55.9          1.47            38.1   4.51e-38\n2 population   0.0000000276 0.0000000546     0.505 6.16e- 1\n\n\n\nPlot by region\n\nggplot(y2k, aes(life_expectancy,log10(population), color=region)) + geom_point() + stat_smooth(method = \"lm\", col = \"blue\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nIf you look at this raw data it appears that the North African data may be skewing the results. Now lets remove the North African data and see if we get as strong of a correlation…\n\ny2kNONA <- y2k %>%\n  filter(region == 'Eastern Africa' | region == 'Middle Africa' | region == 'Southern Africa' | region == 'Western Africa')\n\n\n\nData Plots\n\nggplot(y2kNONA, aes(life_expectancy, infant_mortality, color=region)) + geom_point() + stat_smooth(method = \"lm\", col = \"green\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nggplot(y2kNONA, aes(life_expectancy,log10(population), color=region)) + geom_point() + stat_smooth(method = \"lm\", col = \"blue\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nNow with Northern Africa removed from the model there does appear a negative relationship between life expectancy and population size, similar to what is seen before and after the removal of Northern Africa from the data when evaluating life expectancy and infant mortality."
  },
  {
    "objectID": "dataanalysis_exercise.html",
    "href": "dataanalysis_exercise.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "library(readr)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ dplyr   1.0.10\n✔ tibble  3.1.8      ✔ stringr 1.5.0 \n✔ tidyr   1.3.0      ✔ forcats 0.5.2 \n✔ purrr   1.0.1      \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\n\n\nbotulism <- read_csv(\"dataanalysis-exercise/rawdata/Botulism.csv\")\n\nRows: 2280 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): State, BotType, ToxinType\ndbl (2): Year, Count\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nstr(botulism)\n\nspc_tbl_ [2,280 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ State    : chr [1:2280] \"Alaska\" \"Alaska\" \"Alaska\" \"Alaska\" ...\n $ Year     : num [1:2280] 1947 1948 1950 1952 1956 ...\n $ BotType  : chr [1:2280] \"Foodborne\" \"Foodborne\" \"Foodborne\" \"Foodborne\" ...\n $ ToxinType: chr [1:2280] \"Unknown\" \"Unknown\" \"E\" \"E\" ...\n $ Count    : num [1:2280] 3 4 5 1 5 10 2 1 1 1 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   State = col_character(),\n  ..   Year = col_double(),\n  ..   BotType = col_character(),\n  ..   ToxinType = col_character(),\n  ..   Count = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\nsummary(botulism)\n\n    State                Year        BotType           ToxinType        \n Length:2280        Min.   :1899   Length:2280        Length:2280       \n Class :character   1st Qu.:1976   Class :character   Class :character  \n Mode  :character   Median :1993   Mode  :character   Mode  :character  \n                    Mean   :1986                                        \n                    3rd Qu.:2006                                        \n                    Max.   :2017                                        \n     Count       \n Min.   : 1.000  \n 1st Qu.: 1.000  \n Median : 1.000  \n Mean   : 3.199  \n 3rd Qu.: 3.000  \n Max.   :59.000  \n\nclass(botulism)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n#Overall, the data loaded into R is fairly tidy\n\n\n\n\n\nbotulism [botulism == \"Unknown\"] <- NA\nstr(botulism)\n\nspc_tbl_ [2,280 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ State    : chr [1:2280] \"Alaska\" \"Alaska\" \"Alaska\" \"Alaska\" ...\n $ Year     : num [1:2280] 1947 1948 1950 1952 1956 ...\n $ BotType  : chr [1:2280] \"Foodborne\" \"Foodborne\" \"Foodborne\" \"Foodborne\" ...\n $ ToxinType: chr [1:2280] NA NA \"E\" \"E\" ...\n $ Count    : num [1:2280] 3 4 5 1 5 10 2 1 1 1 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   State = col_character(),\n  ..   Year = col_double(),\n  ..   BotType = col_character(),\n  ..   ToxinType = col_character(),\n  ..   Count = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\n\n\n\nbotulism_na<-na.omit(botulism)\n\n\n\n\n\nbotulism_na <- botulism_na %>%\n  rename(\"Source\"=\"BotType\",\n         \"Strain\"=\"ToxinType\")\n\n\n\n\n\ncondensed_bot<- dplyr::filter(botulism_na, State %in% \n                                c(\"California\", \"Georgia\"))\n\nsummary(condensed_bot)\n\n    State                Year         Source             Strain         \n Length:296         Min.   :1916   Length:296         Length:296        \n Class :character   1st Qu.:1979   Class :character   Class :character  \n Mode  :character   Median :1995   Mode  :character   Mode  :character  \n                    Mean   :1988                                        \n                    3rd Qu.:2007                                        \n                    Max.   :2017                                        \n     Count       \n Min.   : 1.000  \n 1st Qu.: 1.000  \n Median : 3.000  \n Mean   : 7.774  \n 3rd Qu.:13.250  \n Max.   :40.000  \n\n\n\n\n\n\nsaveRDS(condensed_bot, file=\"dataanalysis-exercise/Data/Clean Data/Botulism.RDS\")\n\n\n\n\n\nsumtab_bot= data.frame(do.call(cbind, lapply(condensed_bot, summary)))\nprint(sumtab_bot)\n\n            State             Year    Source    Strain            Count\nMin.          296             1916       296       296                1\n1st Qu. character          1978.75 character character                1\nMedian  character             1995 character character                3\nMean          296 1988.09459459459       296       296 7.77364864864865\n3rd Qu. character             2007 character character            13.25\nMax.    character             2017 character character               40\n\nsaveRDS(sumtab_bot, file= \"dataanalysis-exercise/Data/Summary Table/botsumtable.RDS\")"
  },
  {
    "objectID": "dataanalysis_exercise.html#load-data",
    "href": "dataanalysis_exercise.html#load-data",
    "title": "My Data Analysis Portfolio",
    "section": "Load Data",
    "text": "Load Data\n\ndata<- readRDS(\"dataanalysis-exercise/Data/Clean Data/Botulism.RDS\") #Loading in condensed_bot data from Kim"
  },
  {
    "objectID": "dataanalysis_exercise.html#wrangle-data",
    "href": "dataanalysis_exercise.html#wrangle-data",
    "title": "My Data Analysis Portfolio",
    "section": "Wrangle Data",
    "text": "Wrangle Data\n\ndata2<- data %>%\n  select(Year, Count,State, Source) #Getting rid of Strains\n\ncase_tot<- data2 %>% #This creates a column with the total counts per year instead of separating it by strain. This omits the issue of having multiples of the same year for counts. \n  group_by(Year, State, Source) %>%\n  summarize_if(is.numeric, sum) %>%\n  ungroup()"
  },
  {
    "objectID": "dataanalysis_exercise.html#create-california-and-georgia-specific-dataframes",
    "href": "dataanalysis_exercise.html#create-california-and-georgia-specific-dataframes",
    "title": "My Data Analysis Portfolio",
    "section": "Create California and Georgia Specific Dataframes",
    "text": "Create California and Georgia Specific Dataframes\n\nga<- case_tot %>%\n  filter(State %in% \"Georgia\")\n\nca<- case_tot %>%\n  filter(State %in% \"California\")"
  },
  {
    "objectID": "dataanalysis_exercise.html#botulism-cases-by-state-and-source",
    "href": "dataanalysis_exercise.html#botulism-cases-by-state-and-source",
    "title": "My Data Analysis Portfolio",
    "section": "Botulism Cases By State and Source",
    "text": "Botulism Cases By State and Source\n\ncase_tot %>% ggplot() +geom_line(\n  aes(x = Year,\n      y = Count,\n      color = Source,\n      linetype = State)) +\n  theme_bw() +\n  labs(x = \"Year\",\n       y = \"Case Counts\",\n       title = \"Botulism Cases (1916-2017)\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nCalifornia appears to have a wider range of data collected (across years and different sources). Let’s focus on this State"
  },
  {
    "objectID": "dataanalysis_exercise.html#lets-look-at-botulism-counts-in-california-by-source",
    "href": "dataanalysis_exercise.html#lets-look-at-botulism-counts-in-california-by-source",
    "title": "My Data Analysis Portfolio",
    "section": "Let’s look at Botulism counts in California by Source",
    "text": "Let’s look at Botulism counts in California by Source\n\nca %>% ggplot() +geom_line(\n  aes(x = Year,\n      y = Count,\n      color = Source)) +\n  theme_bw() +\n  labs(x = \"Year\",\n       y = \"Case Counts\",\n       title = \"Botulism Cases in California (1916-2017)\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nIt wasn’t until the 1970’s that other sources of botulism, such as infant cases, were being detected (Rosow,2015) Let’s look at 1980-2020"
  },
  {
    "objectID": "dataanalysis_exercise.html#botulism-cases-in-california-1980-2017",
    "href": "dataanalysis_exercise.html#botulism-cases-in-california-1980-2017",
    "title": "My Data Analysis Portfolio",
    "section": "Botulism Cases in California (1980-2017)",
    "text": "Botulism Cases in California (1980-2017)\n\nca %>% filter(Year %in% (1980:2020)) %>%\n  \nggplot() +geom_boxplot(\n  aes(x = Source,\n      y = Count,\n      color = Source)) +\n  theme_bw() +\n  labs(y = \"Case Counts\",\n       title = \"Botulism Cases in California (1980-2017)\") +\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position = \"none\")\n\n\n\n\nInfant cases seem to be the most common. Looking into this, infants are at a higher risk due to their weakened immune system, lack of gastric acidity, and a diminished bacterial flora(Van Horn, 2022). Let’s go back to the strain data and see which strains are most common in infants"
  },
  {
    "objectID": "dataanalysis_exercise.html#infant-botulism-cases-in-california-by-strain-1980-2017",
    "href": "dataanalysis_exercise.html#infant-botulism-cases-in-california-by-strain-1980-2017",
    "title": "My Data Analysis Portfolio",
    "section": "Infant Botulism Cases in California by Strain (1980-2017)",
    "text": "Infant Botulism Cases in California by Strain (1980-2017)\n\ndata %>% filter(Year %in% (1980:2020),\n                Source %in% \"Infant\") %>% #Taking original dataset and filtering for 1980-2017 and for infant sources\n  \nggplot() +geom_boxplot(\n  aes(x = Strain,\n      y = Count,\n      color = Strain)) +\n  theme_bw() +\n  labs(y = \"Case Counts\",\n       title = \"Infant Botulism Cases in California by Strain (1980-2017)\") +\n  theme(plot.title = element_text(hjust = 0.5),\n       legend.position = \"none\")\n\n\n\n\nStrain A seems to be the most prevalent in infants followed by Strain B. This can be confirmed at https://www.infantbotulism.org/readings/ib_chapter_6th_edition.pdf"
  },
  {
    "objectID": "fluanalysis/code/exploration.html",
    "href": "fluanalysis/code/exploration.html",
    "title": "Brian McKay’s Flu Analysis Data: Exploration",
    "section": "",
    "text": "Let’s Begin with some Data Exploration\nBut first let’s load some packages…\n\nlibrary(gtsummary)\nlibrary(here)\n\nhere() starts at C:/GitHub/MADA/kimberlyperez-MADA-portfolio\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ stringr 1.5.0\n✔ tidyr   1.3.0     ✔ forcats 0.5.2\n✔ readr   2.1.4     \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ggplot2)\n\nAnd Load the Data…\n\nflu<-readRDS(here(\"fluanalysis\",\"processed_data\", \"SympAct_cleaned.rds\")) #Loading in the data\n\nglimpse(flu) #Looking at the Data \n\nRows: 730\nColumns: 32\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n\n\n\n\nLet’s Begin Data Exploration by Creating Summary Tables\nHere I will create summary statistic tables starting with the dataset as a whole and then the important variables\n\nfulldat<- tbl_summary(flu) #Prefer gtsummary to create summary tables over rstatix so i use the tbl_summary function for the whole dataset\nfulldat\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 7301\n    \n  \n  \n    Swollen Lymph Nodes\n312 (43%)\n    Chest Congestion\n407 (56%)\n    Chills/Sweats\n600 (82%)\n    Nasal Congestion\n563 (77%)\n    Cough\n655 (90%)\n    Sneeze\n391 (54%)\n    Fatigue\n666 (91%)\n    Subjective Fever\n500 (68%)\n    Headache\n615 (84%)\n    Weakness\n\n        None\n49 (6.7%)\n        Mild\n223 (31%)\n        Moderate\n338 (46%)\n        Severe\n120 (16%)\n    Weakness\n681 (93%)\n    Cough Severity\n\n        None\n47 (6.4%)\n        Mild\n154 (21%)\n        Moderate\n357 (49%)\n        Severe\n172 (24%)\n    CoughYN2\n683 (94%)\n    Myalgia\n\n        None\n79 (11%)\n        Mild\n213 (29%)\n        Moderate\n325 (45%)\n        Severe\n113 (15%)\n    Myalgia\n651 (89%)\n    Runny Nose\n519 (71%)\n    Abdominal Pain\n91 (12%)\n    Chest Pain\n233 (32%)\n    Diarrhea\n99 (14%)\n    Eye Pain\n113 (15%)\n    Sleeplessness\n415 (57%)\n    Itchy Eyes\n179 (25%)\n    Nausea\n255 (35%)\n    Ear Pain\n162 (22%)\n    Loss of Hearing\n30 (4.1%)\n    Sore Throat\n611 (84%)\n    Breathlessness\n294 (40%)\n    Tooth Pain\n165 (23%)\n    Blurred Vision\n19 (2.6%)\n    Vomiting\n78 (11%)\n    Wheezing\n220 (30%)\n    BodyTemp\n98.50 (98.20, 99.30)\n  \n  \n  \n    \n      1 n (%); Median (IQR)\n    \n  \n\n\n\n#NOTE for KP: Use flextable for customization epiRhandbook\n\nSummary Tables for Body Temperature\n\nsummary (flu$BodyTemp) #Quick and basic overview \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  97.20   98.20   98.50   98.94   99.30  103.10 \n\nbodtemp<- flu %>% tbl_summary(BodyTemp) #Breaking things down a bit more- interesting when broken down by temp group \nbodtemp\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      97.2, N = 21\n      97.3, N = 11\n      97.4, N = 71\n      97.5, N = 91\n      97.6, N = 71\n      97.7, N = 141\n      97.8, N = 231\n      97.9, N = 291\n      98, N = 301\n      98.1, N = 461\n      98.2, N = 501\n      98.3, N = 621\n      98.4, N = 401\n      98.5, N = 531\n      98.6, N = 271\n      98.7, N = 351\n      98.8, N = 241\n      98.9, N = 231\n      99, N = 251\n      99.1, N = 151\n      99.2, N = 201\n      99.3, N = 181\n      99.4, N = 111\n      99.5, N = 141\n      99.6, N = 61\n      99.7, N = 111\n      99.8, N = 61\n      99.9, N = 101\n      100, N = 71\n      100.1, N = 71\n      100.2, N = 81\n      100.3, N = 51\n      100.4, N = 71\n      100.5, N = 51\n      100.6, N = 41\n      100.8, N = 21\n      100.9, N = 91\n      101, N = 21\n      101.1, N = 31\n      101.2, N = 41\n      101.3, N = 11\n      101.5, N = 21\n      101.6, N = 21\n      101.7, N = 31\n      101.8, N = 41\n      101.9, N = 61\n      102, N = 21\n      102.1, N = 21\n      102.2, N = 31\n      102.4, N = 21\n      102.5, N = 21\n      102.6, N = 31\n      102.7, N = 21\n      102.8, N = 51\n      102.9, N = 11\n      103, N = 71\n      103.1, N = 21\n    \n  \n  \n    Swollen Lymph Nodes\n2 (100%)\n1 (100%)\n3 (43%)\n4 (44%)\n2 (29%)\n7 (50%)\n9 (39%)\n16 (55%)\n14 (47%)\n19 (41%)\n22 (44%)\n25 (40%)\n18 (45%)\n29 (55%)\n9 (33%)\n10 (29%)\n11 (46%)\n10 (43%)\n8 (32%)\n9 (60%)\n11 (55%)\n6 (33%)\n7 (64%)\n3 (21%)\n1 (17%)\n5 (45%)\n2 (33%)\n3 (30%)\n2 (29%)\n5 (71%)\n2 (25%)\n3 (60%)\n2 (29%)\n3 (60%)\n1 (25%)\n1 (50%)\n4 (44%)\n1 (50%)\n1 (33%)\n2 (50%)\n0 (0%)\n1 (50%)\n0 (0%)\n1 (33%)\n0 (0%)\n3 (50%)\n0 (0%)\n1 (50%)\n1 (33%)\n2 (100%)\n1 (50%)\n1 (33%)\n1 (50%)\n3 (60%)\n0 (0%)\n3 (43%)\n1 (50%)\n    Chest Congestion\n1 (50%)\n1 (100%)\n5 (71%)\n6 (67%)\n2 (29%)\n10 (71%)\n10 (43%)\n13 (45%)\n18 (60%)\n22 (48%)\n23 (46%)\n35 (56%)\n22 (55%)\n28 (53%)\n13 (48%)\n19 (54%)\n13 (54%)\n16 (70%)\n15 (60%)\n11 (73%)\n11 (55%)\n9 (50%)\n5 (45%)\n9 (64%)\n2 (33%)\n7 (64%)\n6 (100%)\n6 (60%)\n5 (71%)\n6 (86%)\n2 (25%)\n5 (100%)\n5 (71%)\n2 (40%)\n4 (100%)\n2 (100%)\n7 (78%)\n2 (100%)\n3 (100%)\n2 (50%)\n0 (0%)\n0 (0%)\n2 (100%)\n2 (67%)\n1 (25%)\n3 (50%)\n1 (50%)\n0 (0%)\n1 (33%)\n2 (100%)\n1 (50%)\n1 (33%)\n1 (50%)\n2 (40%)\n1 (100%)\n6 (86%)\n0 (0%)\n    Chills/Sweats\n2 (100%)\n0 (0%)\n4 (57%)\n7 (78%)\n6 (86%)\n9 (64%)\n17 (74%)\n18 (62%)\n23 (77%)\n27 (59%)\n40 (80%)\n46 (74%)\n36 (90%)\n47 (89%)\n26 (96%)\n32 (91%)\n23 (96%)\n21 (91%)\n23 (92%)\n14 (93%)\n16 (80%)\n13 (72%)\n10 (91%)\n13 (93%)\n5 (83%)\n11 (100%)\n5 (83%)\n8 (80%)\n7 (100%)\n7 (100%)\n7 (88%)\n4 (80%)\n4 (57%)\n5 (100%)\n2 (50%)\n1 (50%)\n9 (100%)\n2 (100%)\n3 (100%)\n3 (75%)\n1 (100%)\n1 (50%)\n2 (100%)\n3 (100%)\n2 (50%)\n5 (83%)\n2 (100%)\n2 (100%)\n3 (100%)\n1 (50%)\n2 (100%)\n3 (100%)\n2 (100%)\n5 (100%)\n1 (100%)\n7 (100%)\n2 (100%)\n    Nasal Congestion\n2 (100%)\n1 (100%)\n7 (100%)\n9 (100%)\n5 (71%)\n13 (93%)\n20 (87%)\n20 (69%)\n23 (77%)\n34 (74%)\n37 (74%)\n51 (82%)\n31 (78%)\n46 (87%)\n23 (85%)\n24 (69%)\n20 (83%)\n16 (70%)\n17 (68%)\n14 (93%)\n15 (75%)\n12 (67%)\n10 (91%)\n9 (64%)\n4 (67%)\n9 (82%)\n6 (100%)\n6 (60%)\n5 (71%)\n6 (86%)\n7 (88%)\n4 (80%)\n4 (57%)\n4 (80%)\n4 (100%)\n1 (50%)\n7 (78%)\n2 (100%)\n3 (100%)\n3 (75%)\n0 (0%)\n2 (100%)\n1 (50%)\n3 (100%)\n1 (25%)\n4 (67%)\n1 (50%)\n1 (50%)\n1 (33%)\n1 (50%)\n1 (50%)\n2 (67%)\n1 (50%)\n2 (40%)\n1 (100%)\n7 (100%)\n0 (0%)\n    Cough\n2 (100%)\n1 (100%)\n7 (100%)\n8 (89%)\n6 (86%)\n13 (93%)\n17 (74%)\n25 (86%)\n27 (90%)\n40 (87%)\n42 (84%)\n56 (90%)\n37 (92%)\n50 (94%)\n22 (81%)\n28 (80%)\n22 (92%)\n22 (96%)\n21 (84%)\n14 (93%)\n18 (90%)\n17 (94%)\n11 (100%)\n13 (93%)\n5 (83%)\n11 (100%)\n6 (100%)\n9 (90%)\n7 (100%)\n7 (100%)\n7 (88%)\n5 (100%)\n7 (100%)\n4 (80%)\n4 (100%)\n1 (50%)\n9 (100%)\n2 (100%)\n3 (100%)\n4 (100%)\n1 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n3 (75%)\n6 (100%)\n2 (100%)\n1 (50%)\n3 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n2 (100%)\n3 (60%)\n1 (100%)\n7 (100%)\n2 (100%)\n    Sneeze\n1 (50%)\n1 (100%)\n5 (71%)\n6 (67%)\n4 (57%)\n11 (79%)\n15 (65%)\n12 (41%)\n20 (67%)\n23 (50%)\n29 (58%)\n35 (56%)\n26 (65%)\n35 (66%)\n16 (59%)\n22 (63%)\n14 (58%)\n8 (35%)\n12 (48%)\n9 (60%)\n7 (35%)\n11 (61%)\n3 (27%)\n6 (43%)\n1 (17%)\n6 (55%)\n5 (83%)\n2 (20%)\n4 (57%)\n3 (43%)\n6 (75%)\n4 (80%)\n2 (29%)\n2 (40%)\n2 (50%)\n1 (50%)\n4 (44%)\n1 (50%)\n2 (67%)\n0 (0%)\n0 (0%)\n2 (100%)\n1 (50%)\n2 (67%)\n0 (0%)\n3 (50%)\n1 (50%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (33%)\n1 (50%)\n0 (0%)\n0 (0%)\n3 (43%)\n0 (0%)\n    Fatigue\n2 (100%)\n1 (100%)\n6 (86%)\n9 (100%)\n6 (86%)\n11 (79%)\n23 (100%)\n24 (83%)\n25 (83%)\n39 (85%)\n41 (82%)\n56 (90%)\n37 (92%)\n51 (96%)\n25 (93%)\n35 (100%)\n23 (96%)\n21 (91%)\n23 (92%)\n14 (93%)\n18 (90%)\n15 (83%)\n10 (91%)\n11 (79%)\n6 (100%)\n11 (100%)\n5 (83%)\n10 (100%)\n7 (100%)\n7 (100%)\n8 (100%)\n5 (100%)\n7 (100%)\n4 (80%)\n3 (75%)\n2 (100%)\n9 (100%)\n1 (50%)\n3 (100%)\n4 (100%)\n1 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n4 (100%)\n6 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n1 (50%)\n2 (100%)\n3 (100%)\n2 (100%)\n5 (100%)\n1 (100%)\n7 (100%)\n2 (100%)\n    Subjective Fever\n1 (50%)\n0 (0%)\n3 (43%)\n2 (22%)\n3 (43%)\n9 (64%)\n14 (61%)\n14 (48%)\n19 (63%)\n21 (46%)\n29 (58%)\n39 (63%)\n34 (85%)\n40 (75%)\n16 (59%)\n27 (77%)\n20 (83%)\n17 (74%)\n17 (68%)\n11 (73%)\n13 (65%)\n12 (67%)\n11 (100%)\n9 (64%)\n5 (83%)\n8 (73%)\n3 (50%)\n6 (60%)\n5 (71%)\n6 (86%)\n7 (88%)\n3 (60%)\n7 (100%)\n5 (100%)\n2 (50%)\n2 (100%)\n9 (100%)\n2 (100%)\n3 (100%)\n3 (75%)\n1 (100%)\n2 (100%)\n2 (100%)\n2 (67%)\n3 (75%)\n5 (83%)\n2 (100%)\n2 (100%)\n3 (100%)\n1 (50%)\n2 (100%)\n2 (67%)\n2 (100%)\n5 (100%)\n1 (100%)\n6 (86%)\n2 (100%)\n    Headache\n2 (100%)\n1 (100%)\n4 (57%)\n7 (78%)\n6 (86%)\n13 (93%)\n20 (87%)\n23 (79%)\n24 (80%)\n37 (80%)\n39 (78%)\n50 (81%)\n35 (88%)\n47 (89%)\n22 (81%)\n30 (86%)\n21 (88%)\n16 (70%)\n23 (92%)\n12 (80%)\n19 (95%)\n17 (94%)\n10 (91%)\n13 (93%)\n6 (100%)\n7 (64%)\n5 (83%)\n8 (80%)\n6 (86%)\n7 (100%)\n8 (100%)\n5 (100%)\n7 (100%)\n4 (80%)\n4 (100%)\n2 (100%)\n8 (89%)\n2 (100%)\n3 (100%)\n2 (50%)\n1 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n4 (100%)\n3 (50%)\n1 (50%)\n2 (100%)\n3 (100%)\n1 (50%)\n1 (50%)\n2 (67%)\n1 (50%)\n5 (100%)\n1 (100%)\n7 (100%)\n1 (50%)\n    Weakness\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        None\n1 (50%)\n0 (0%)\n0 (0%)\n3 (33%)\n0 (0%)\n3 (21%)\n1 (4.3%)\n4 (14%)\n3 (10%)\n2 (4.3%)\n5 (10%)\n5 (8.1%)\n1 (2.5%)\n2 (3.8%)\n1 (3.7%)\n2 (5.7%)\n0 (0%)\n4 (17%)\n2 (8.0%)\n0 (0%)\n0 (0%)\n1 (5.6%)\n1 (9.1%)\n2 (14%)\n0 (0%)\n1 (9.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (14%)\n1 (12%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n        Mild\n0 (0%)\n0 (0%)\n1 (14%)\n3 (33%)\n3 (43%)\n4 (29%)\n6 (26%)\n10 (34%)\n12 (40%)\n16 (35%)\n20 (40%)\n19 (31%)\n15 (38%)\n18 (34%)\n7 (26%)\n15 (43%)\n3 (12%)\n5 (22%)\n8 (32%)\n5 (33%)\n4 (20%)\n5 (28%)\n3 (27%)\n3 (21%)\n3 (50%)\n1 (9.1%)\n1 (17%)\n4 (40%)\n4 (57%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (14%)\n3 (60%)\n1 (25%)\n0 (0%)\n2 (22%)\n0 (0%)\n2 (67%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n1 (33%)\n1 (25%)\n2 (33%)\n0 (0%)\n2 (100%)\n1 (33%)\n0 (0%)\n1 (50%)\n1 (33%)\n1 (50%)\n2 (40%)\n1 (100%)\n1 (14%)\n1 (50%)\n        Moderate\n1 (50%)\n1 (100%)\n5 (71%)\n3 (33%)\n1 (14%)\n4 (29%)\n11 (48%)\n12 (41%)\n15 (50%)\n25 (54%)\n20 (40%)\n32 (52%)\n15 (38%)\n24 (45%)\n14 (52%)\n11 (31%)\n13 (54%)\n13 (57%)\n9 (36%)\n9 (60%)\n9 (45%)\n11 (61%)\n7 (64%)\n5 (36%)\n2 (33%)\n7 (64%)\n4 (67%)\n6 (60%)\n3 (43%)\n3 (43%)\n5 (62%)\n4 (80%)\n2 (29%)\n1 (20%)\n2 (50%)\n0 (0%)\n6 (67%)\n1 (50%)\n0 (0%)\n4 (100%)\n0 (0%)\n2 (100%)\n1 (50%)\n0 (0%)\n1 (25%)\n1 (17%)\n2 (100%)\n0 (0%)\n2 (67%)\n0 (0%)\n1 (50%)\n1 (33%)\n1 (50%)\n2 (40%)\n0 (0%)\n3 (43%)\n1 (50%)\n        Severe\n0 (0%)\n0 (0%)\n1 (14%)\n0 (0%)\n3 (43%)\n3 (21%)\n5 (22%)\n3 (10%)\n0 (0%)\n3 (6.5%)\n5 (10%)\n6 (9.7%)\n9 (22%)\n9 (17%)\n5 (19%)\n7 (20%)\n8 (33%)\n1 (4.3%)\n6 (24%)\n1 (6.7%)\n7 (35%)\n1 (5.6%)\n0 (0%)\n4 (29%)\n1 (17%)\n2 (18%)\n1 (17%)\n0 (0%)\n0 (0%)\n3 (43%)\n2 (25%)\n1 (20%)\n4 (57%)\n1 (20%)\n1 (25%)\n1 (50%)\n1 (11%)\n0 (0%)\n1 (33%)\n0 (0%)\n1 (100%)\n0 (0%)\n0 (0%)\n2 (67%)\n2 (50%)\n3 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n1 (33%)\n0 (0%)\n1 (20%)\n0 (0%)\n3 (43%)\n0 (0%)\n    Weakness\n1 (50%)\n1 (100%)\n7 (100%)\n6 (67%)\n7 (100%)\n11 (79%)\n22 (96%)\n25 (86%)\n27 (90%)\n44 (96%)\n45 (90%)\n57 (92%)\n39 (98%)\n51 (96%)\n26 (96%)\n33 (94%)\n24 (100%)\n19 (83%)\n23 (92%)\n15 (100%)\n20 (100%)\n17 (94%)\n10 (91%)\n12 (86%)\n6 (100%)\n10 (91%)\n6 (100%)\n10 (100%)\n7 (100%)\n6 (86%)\n7 (88%)\n5 (100%)\n7 (100%)\n5 (100%)\n4 (100%)\n1 (50%)\n9 (100%)\n1 (50%)\n3 (100%)\n4 (100%)\n1 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n4 (100%)\n6 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n1 (50%)\n2 (100%)\n3 (100%)\n2 (100%)\n5 (100%)\n1 (100%)\n7 (100%)\n2 (100%)\n    Cough Severity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        None\n0 (0%)\n0 (0%)\n0 (0%)\n1 (11%)\n0 (0%)\n1 (7.1%)\n5 (22%)\n3 (10%)\n3 (10%)\n5 (11%)\n3 (6.0%)\n4 (6.5%)\n2 (5.0%)\n1 (1.9%)\n1 (3.7%)\n5 (14%)\n0 (0%)\n1 (4.3%)\n2 (8.0%)\n1 (6.7%)\n2 (10%)\n1 (5.6%)\n0 (0%)\n1 (7.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (10%)\n0 (0%)\n0 (0%)\n1 (12%)\n0 (0%)\n0 (0%)\n1 (20%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (40%)\n0 (0%)\n0 (0%)\n0 (0%)\n        Mild\n0 (0%)\n0 (0%)\n2 (29%)\n4 (44%)\n3 (43%)\n2 (14%)\n5 (22%)\n8 (28%)\n7 (23%)\n11 (24%)\n11 (22%)\n9 (15%)\n6 (15%)\n12 (23%)\n7 (26%)\n8 (23%)\n8 (33%)\n2 (8.7%)\n5 (20%)\n4 (27%)\n6 (30%)\n2 (11%)\n2 (18%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (17%)\n1 (10%)\n1 (14%)\n1 (14%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (20%)\n1 (25%)\n1 (50%)\n3 (33%)\n0 (0%)\n0 (0%)\n1 (25%)\n1 (100%)\n1 (50%)\n1 (50%)\n2 (67%)\n3 (75%)\n2 (33%)\n1 (50%)\n1 (50%)\n1 (33%)\n0 (0%)\n0 (0%)\n1 (33%)\n0 (0%)\n1 (20%)\n0 (0%)\n3 (43%)\n1 (50%)\n        Moderate\n2 (100%)\n1 (100%)\n4 (57%)\n2 (22%)\n3 (43%)\n6 (43%)\n7 (30%)\n10 (34%)\n13 (43%)\n19 (41%)\n28 (56%)\n38 (61%)\n23 (57%)\n28 (53%)\n13 (48%)\n12 (34%)\n9 (38%)\n17 (74%)\n15 (60%)\n6 (40%)\n9 (45%)\n9 (50%)\n6 (55%)\n9 (64%)\n3 (50%)\n7 (64%)\n4 (67%)\n6 (60%)\n2 (29%)\n5 (71%)\n5 (62%)\n4 (80%)\n3 (43%)\n3 (60%)\n2 (50%)\n0 (0%)\n2 (22%)\n1 (50%)\n0 (0%)\n1 (25%)\n0 (0%)\n1 (50%)\n0 (0%)\n1 (33%)\n1 (25%)\n1 (17%)\n0 (0%)\n1 (50%)\n2 (67%)\n2 (100%)\n1 (50%)\n2 (67%)\n1 (50%)\n2 (40%)\n1 (100%)\n3 (43%)\n1 (50%)\n        Severe\n0 (0%)\n0 (0%)\n1 (14%)\n2 (22%)\n1 (14%)\n5 (36%)\n6 (26%)\n8 (28%)\n7 (23%)\n11 (24%)\n8 (16%)\n11 (18%)\n9 (22%)\n12 (23%)\n6 (22%)\n10 (29%)\n7 (29%)\n3 (13%)\n3 (12%)\n4 (27%)\n3 (15%)\n6 (33%)\n3 (27%)\n4 (29%)\n3 (50%)\n4 (36%)\n1 (17%)\n2 (20%)\n4 (57%)\n1 (14%)\n2 (25%)\n1 (20%)\n4 (57%)\n0 (0%)\n1 (25%)\n1 (50%)\n4 (44%)\n1 (50%)\n3 (100%)\n2 (50%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n3 (50%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (14%)\n0 (0%)\n    CoughYN2\n2 (100%)\n1 (100%)\n7 (100%)\n8 (89%)\n7 (100%)\n13 (93%)\n18 (78%)\n26 (90%)\n27 (90%)\n41 (89%)\n47 (94%)\n58 (94%)\n38 (95%)\n52 (98%)\n26 (96%)\n30 (86%)\n24 (100%)\n22 (96%)\n23 (92%)\n14 (93%)\n18 (90%)\n17 (94%)\n11 (100%)\n13 (93%)\n6 (100%)\n11 (100%)\n6 (100%)\n9 (90%)\n7 (100%)\n7 (100%)\n7 (88%)\n5 (100%)\n7 (100%)\n4 (80%)\n4 (100%)\n2 (100%)\n9 (100%)\n2 (100%)\n3 (100%)\n4 (100%)\n1 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n4 (100%)\n6 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n2 (100%)\n3 (60%)\n1 (100%)\n7 (100%)\n2 (100%)\n    Myalgia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        None\n1 (50%)\n0 (0%)\n2 (29%)\n2 (22%)\n1 (14%)\n3 (21%)\n1 (4.3%)\n6 (21%)\n4 (13%)\n9 (20%)\n8 (16%)\n8 (13%)\n3 (7.5%)\n5 (9.4%)\n0 (0%)\n4 (11%)\n1 (4.2%)\n2 (8.7%)\n0 (0%)\n2 (13%)\n1 (5.0%)\n1 (5.6%)\n1 (9.1%)\n2 (14%)\n0 (0%)\n0 (0%)\n1 (17%)\n0 (0%)\n1 (14%)\n1 (14%)\n0 (0%)\n0 (0%)\n2 (29%)\n2 (40%)\n0 (0%)\n0 (0%)\n2 (22%)\n0 (0%)\n0 (0%)\n1 (25%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (100%)\n0 (0%)\n0 (0%)\n        Mild\n0 (0%)\n0 (0%)\n1 (14%)\n3 (33%)\n0 (0%)\n4 (29%)\n6 (26%)\n9 (31%)\n12 (40%)\n12 (26%)\n16 (32%)\n21 (34%)\n13 (32%)\n15 (28%)\n8 (30%)\n9 (26%)\n2 (8.3%)\n6 (26%)\n11 (44%)\n5 (33%)\n3 (15%)\n7 (39%)\n4 (36%)\n4 (29%)\n3 (50%)\n1 (9.1%)\n1 (17%)\n5 (50%)\n3 (43%)\n0 (0%)\n1 (12%)\n2 (40%)\n0 (0%)\n2 (40%)\n0 (0%)\n1 (50%)\n2 (22%)\n1 (50%)\n2 (67%)\n1 (25%)\n0 (0%)\n1 (50%)\n0 (0%)\n1 (33%)\n0 (0%)\n2 (33%)\n1 (50%)\n1 (50%)\n1 (33%)\n0 (0%)\n1 (50%)\n2 (67%)\n2 (100%)\n1 (20%)\n0 (0%)\n4 (57%)\n0 (0%)\n        Moderate\n1 (50%)\n1 (100%)\n2 (29%)\n4 (44%)\n4 (57%)\n5 (36%)\n13 (57%)\n11 (38%)\n13 (43%)\n21 (46%)\n20 (40%)\n30 (48%)\n16 (40%)\n28 (53%)\n9 (33%)\n13 (37%)\n14 (58%)\n14 (61%)\n7 (28%)\n7 (47%)\n7 (35%)\n9 (50%)\n5 (45%)\n4 (29%)\n3 (50%)\n10 (91%)\n2 (33%)\n2 (20%)\n3 (43%)\n4 (57%)\n5 (62%)\n2 (40%)\n3 (43%)\n1 (20%)\n3 (75%)\n0 (0%)\n4 (44%)\n1 (50%)\n0 (0%)\n2 (50%)\n0 (0%)\n1 (50%)\n2 (100%)\n2 (67%)\n3 (75%)\n1 (17%)\n1 (50%)\n1 (50%)\n2 (67%)\n0 (0%)\n0 (0%)\n1 (33%)\n0 (0%)\n3 (60%)\n0 (0%)\n3 (43%)\n2 (100%)\n        Severe\n0 (0%)\n0 (0%)\n2 (29%)\n0 (0%)\n2 (29%)\n2 (14%)\n3 (13%)\n3 (10%)\n1 (3.3%)\n4 (8.7%)\n6 (12%)\n3 (4.8%)\n8 (20%)\n5 (9.4%)\n10 (37%)\n9 (26%)\n7 (29%)\n1 (4.3%)\n7 (28%)\n1 (6.7%)\n9 (45%)\n1 (5.6%)\n1 (9.1%)\n4 (29%)\n0 (0%)\n0 (0%)\n2 (33%)\n3 (30%)\n0 (0%)\n2 (29%)\n2 (25%)\n1 (20%)\n2 (29%)\n0 (0%)\n1 (25%)\n1 (50%)\n1 (11%)\n0 (0%)\n1 (33%)\n0 (0%)\n1 (100%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (25%)\n3 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (20%)\n0 (0%)\n0 (0%)\n0 (0%)\n    Myalgia\n1 (50%)\n1 (100%)\n5 (71%)\n7 (78%)\n6 (86%)\n11 (79%)\n22 (96%)\n23 (79%)\n26 (87%)\n37 (80%)\n42 (84%)\n54 (87%)\n37 (92%)\n48 (91%)\n27 (100%)\n31 (89%)\n23 (96%)\n21 (91%)\n25 (100%)\n13 (87%)\n19 (95%)\n17 (94%)\n10 (91%)\n12 (86%)\n6 (100%)\n11 (100%)\n5 (83%)\n10 (100%)\n6 (86%)\n6 (86%)\n8 (100%)\n5 (100%)\n5 (71%)\n3 (60%)\n4 (100%)\n2 (100%)\n7 (78%)\n2 (100%)\n3 (100%)\n3 (75%)\n1 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n4 (100%)\n6 (100%)\n2 (100%)\n2 (100%)\n3 (100%)\n1 (50%)\n2 (100%)\n3 (100%)\n2 (100%)\n5 (100%)\n0 (0%)\n7 (100%)\n2 (100%)\n    Runny Nose\n1 (50%)\n1 (100%)\n7 (100%)\n7 (78%)\n4 (57%)\n12 (86%)\n14 (61%)\n20 (69%)\n23 (77%)\n33 (72%)\n43 (86%)\n46 (74%)\n30 (75%)\n43 (81%)\n21 (78%)\n25 (71%)\n15 (62%)\n15 (65%)\n18 (72%)\n11 (73%)\n13 (65%)\n12 (67%)\n7 (64%)\n8 (57%)\n2 (33%)\n7 (64%)\n5 (83%)\n5 (50%)\n5 (71%)\n5 (71%)\n4 (50%)\n5 (100%)\n3 (43%)\n4 (80%)\n4 (100%)\n1 (50%)\n5 (56%)\n2 (100%)\n2 (67%)\n3 (75%)\n0 (0%)\n2 (100%)\n1 (50%)\n3 (100%)\n2 (50%)\n2 (33%)\n0 (0%)\n1 (50%)\n2 (67%)\n1 (50%)\n1 (50%)\n2 (67%)\n2 (100%)\n2 (40%)\n1 (100%)\n6 (86%)\n0 (0%)\n    Abdominal Pain\n1 (50%)\n0 (0%)\n1 (14%)\n1 (11%)\n0 (0%)\n3 (21%)\n2 (8.7%)\n2 (6.9%)\n6 (20%)\n4 (8.7%)\n6 (12%)\n6 (9.7%)\n3 (7.5%)\n4 (7.5%)\n5 (19%)\n6 (17%)\n5 (21%)\n3 (13%)\n2 (8.0%)\n0 (0%)\n4 (20%)\n1 (5.6%)\n1 (9.1%)\n2 (14%)\n0 (0%)\n1 (9.1%)\n1 (17%)\n2 (20%)\n2 (29%)\n0 (0%)\n1 (12%)\n0 (0%)\n2 (29%)\n1 (20%)\n0 (0%)\n1 (50%)\n2 (22%)\n0 (0%)\n1 (33%)\n1 (25%)\n1 (100%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (25%)\n1 (17%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n1 (50%)\n1 (33%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (29%)\n0 (0%)\n    Chest Pain\n1 (50%)\n1 (100%)\n0 (0%)\n1 (11%)\n2 (29%)\n6 (43%)\n9 (39%)\n6 (21%)\n8 (27%)\n12 (26%)\n14 (28%)\n14 (23%)\n17 (42%)\n19 (36%)\n7 (26%)\n12 (34%)\n7 (29%)\n7 (30%)\n9 (36%)\n4 (27%)\n7 (35%)\n6 (33%)\n2 (18%)\n4 (29%)\n2 (33%)\n4 (36%)\n2 (33%)\n5 (50%)\n3 (43%)\n2 (29%)\n3 (38%)\n5 (100%)\n3 (43%)\n2 (40%)\n2 (50%)\n1 (50%)\n3 (33%)\n2 (100%)\n1 (33%)\n4 (100%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (33%)\n1 (25%)\n4 (67%)\n1 (50%)\n1 (50%)\n0 (0%)\n2 (100%)\n2 (100%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (14%)\n0 (0%)\n    Diarrhea\n1 (50%)\n0 (0%)\n3 (43%)\n2 (22%)\n0 (0%)\n2 (14%)\n4 (17%)\n3 (10%)\n3 (10%)\n5 (11%)\n9 (18%)\n11 (18%)\n4 (10%)\n7 (13%)\n1 (3.7%)\n9 (26%)\n2 (8.3%)\n2 (8.7%)\n4 (16%)\n2 (13%)\n1 (5.0%)\n2 (11%)\n1 (9.1%)\n2 (14%)\n2 (33%)\n2 (18%)\n1 (17%)\n1 (10%)\n1 (14%)\n1 (14%)\n2 (25%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (25%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (33%)\n0 (0%)\n1 (100%)\n1 (50%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (29%)\n0 (0%)\n    Eye Pain\n0 (0%)\n1 (100%)\n1 (14%)\n3 (33%)\n1 (14%)\n3 (21%)\n3 (13%)\n4 (14%)\n3 (10%)\n6 (13%)\n8 (16%)\n6 (9.7%)\n4 (10%)\n7 (13%)\n4 (15%)\n6 (17%)\n7 (29%)\n6 (26%)\n2 (8.0%)\n1 (6.7%)\n3 (15%)\n2 (11%)\n4 (36%)\n2 (14%)\n0 (0%)\n1 (9.1%)\n3 (50%)\n0 (0%)\n3 (43%)\n0 (0%)\n2 (25%)\n0 (0%)\n1 (14%)\n1 (20%)\n0 (0%)\n1 (50%)\n2 (22%)\n1 (50%)\n3 (100%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (33%)\n0 (0%)\n0 (0%)\n1 (50%)\n1 (50%)\n1 (33%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (20%)\n1 (100%)\n1 (14%)\n0 (0%)\n    Sleeplessness\n0 (0%)\n0 (0%)\n2 (29%)\n4 (44%)\n3 (43%)\n9 (64%)\n13 (57%)\n17 (59%)\n18 (60%)\n22 (48%)\n28 (56%)\n40 (65%)\n22 (55%)\n33 (62%)\n15 (56%)\n18 (51%)\n20 (83%)\n13 (57%)\n19 (76%)\n5 (33%)\n11 (55%)\n9 (50%)\n4 (36%)\n6 (43%)\n4 (67%)\n6 (55%)\n4 (67%)\n5 (50%)\n5 (71%)\n2 (29%)\n6 (75%)\n4 (80%)\n5 (71%)\n4 (80%)\n2 (50%)\n2 (100%)\n3 (33%)\n0 (0%)\n2 (67%)\n2 (50%)\n1 (100%)\n1 (50%)\n0 (0%)\n2 (67%)\n1 (25%)\n6 (100%)\n1 (50%)\n1 (50%)\n1 (33%)\n1 (50%)\n1 (50%)\n2 (67%)\n2 (100%)\n3 (60%)\n0 (0%)\n4 (57%)\n1 (50%)\n    Itchy Eyes\n0 (0%)\n0 (0%)\n1 (14%)\n4 (44%)\n2 (29%)\n5 (36%)\n7 (30%)\n7 (24%)\n6 (20%)\n8 (17%)\n13 (26%)\n16 (26%)\n8 (20%)\n14 (26%)\n6 (22%)\n8 (23%)\n9 (38%)\n7 (30%)\n5 (20%)\n3 (20%)\n6 (30%)\n4 (22%)\n5 (45%)\n3 (21%)\n0 (0%)\n4 (36%)\n3 (50%)\n1 (10%)\n2 (29%)\n2 (29%)\n2 (25%)\n0 (0%)\n2 (29%)\n1 (20%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (67%)\n0 (0%)\n0 (0%)\n1 (50%)\n1 (50%)\n1 (33%)\n0 (0%)\n2 (33%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (33%)\n1 (50%)\n3 (60%)\n1 (100%)\n2 (29%)\n0 (0%)\n    Nausea\n0 (0%)\n0 (0%)\n5 (71%)\n2 (22%)\n2 (29%)\n1 (7.1%)\n11 (48%)\n4 (14%)\n11 (37%)\n18 (39%)\n18 (36%)\n18 (29%)\n9 (22%)\n20 (38%)\n13 (48%)\n15 (43%)\n13 (54%)\n7 (30%)\n8 (32%)\n4 (27%)\n9 (45%)\n6 (33%)\n2 (18%)\n5 (36%)\n2 (33%)\n4 (36%)\n1 (17%)\n5 (50%)\n2 (29%)\n3 (43%)\n3 (38%)\n3 (60%)\n2 (29%)\n3 (60%)\n0 (0%)\n2 (100%)\n3 (33%)\n2 (100%)\n1 (33%)\n1 (25%)\n1 (100%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (25%)\n4 (67%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (40%)\n0 (0%)\n6 (86%)\n0 (0%)\n    Ear Pain\n0 (0%)\n0 (0%)\n2 (29%)\n1 (11%)\n2 (29%)\n5 (36%)\n7 (30%)\n8 (28%)\n7 (23%)\n8 (17%)\n7 (14%)\n8 (13%)\n10 (25%)\n13 (25%)\n3 (11%)\n4 (11%)\n9 (38%)\n3 (13%)\n6 (24%)\n3 (20%)\n5 (25%)\n5 (28%)\n0 (0%)\n6 (43%)\n1 (17%)\n3 (27%)\n3 (50%)\n3 (30%)\n1 (14%)\n4 (57%)\n3 (38%)\n2 (40%)\n2 (29%)\n1 (20%)\n1 (25%)\n0 (0%)\n3 (33%)\n1 (50%)\n1 (33%)\n1 (25%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (25%)\n2 (33%)\n0 (0%)\n0 (0%)\n1 (33%)\n1 (50%)\n0 (0%)\n2 (67%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (14%)\n0 (0%)\n    Loss of Hearing\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (14%)\n1 (4.3%)\n0 (0%)\n0 (0%)\n0 (0%)\n3 (6.0%)\n0 (0%)\n1 (2.5%)\n2 (3.8%)\n2 (7.4%)\n1 (2.9%)\n1 (4.2%)\n3 (13%)\n1 (4.0%)\n4 (27%)\n0 (0%)\n1 (5.6%)\n0 (0%)\n2 (14%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (25%)\n0 (0%)\n2 (29%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (25%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n    Sore Throat\n1 (50%)\n1 (100%)\n4 (57%)\n8 (89%)\n6 (86%)\n11 (79%)\n19 (83%)\n25 (86%)\n24 (80%)\n39 (85%)\n42 (84%)\n49 (79%)\n34 (85%)\n44 (83%)\n20 (74%)\n25 (71%)\n22 (92%)\n20 (87%)\n21 (84%)\n14 (93%)\n18 (90%)\n14 (78%)\n10 (91%)\n10 (71%)\n6 (100%)\n9 (82%)\n4 (67%)\n9 (90%)\n5 (71%)\n7 (100%)\n7 (88%)\n5 (100%)\n7 (100%)\n4 (80%)\n4 (100%)\n2 (100%)\n8 (89%)\n2 (100%)\n3 (100%)\n4 (100%)\n0 (0%)\n2 (100%)\n2 (100%)\n3 (100%)\n3 (75%)\n6 (100%)\n1 (50%)\n2 (100%)\n1 (33%)\n2 (100%)\n2 (100%)\n3 (100%)\n2 (100%)\n5 (100%)\n1 (100%)\n7 (100%)\n2 (100%)\n    Breathlessness\n2 (100%)\n0 (0%)\n1 (14%)\n4 (44%)\n3 (43%)\n6 (43%)\n16 (70%)\n10 (34%)\n9 (30%)\n17 (37%)\n19 (38%)\n19 (31%)\n12 (30%)\n22 (42%)\n11 (41%)\n10 (29%)\n12 (50%)\n10 (43%)\n11 (44%)\n8 (53%)\n10 (50%)\n6 (33%)\n6 (55%)\n4 (29%)\n3 (50%)\n3 (27%)\n4 (67%)\n4 (40%)\n4 (57%)\n4 (57%)\n3 (38%)\n2 (40%)\n3 (43%)\n3 (60%)\n1 (25%)\n1 (50%)\n5 (56%)\n2 (100%)\n1 (33%)\n2 (50%)\n0 (0%)\n1 (50%)\n1 (50%)\n1 (33%)\n0 (0%)\n5 (83%)\n1 (50%)\n1 (50%)\n0 (0%)\n2 (100%)\n1 (50%)\n0 (0%)\n1 (50%)\n3 (60%)\n1 (100%)\n2 (29%)\n1 (50%)\n    Tooth Pain\n1 (50%)\n0 (0%)\n1 (14%)\n2 (22%)\n1 (14%)\n4 (29%)\n1 (4.3%)\n7 (24%)\n5 (17%)\n11 (24%)\n12 (24%)\n12 (19%)\n9 (22%)\n15 (28%)\n7 (26%)\n8 (23%)\n10 (42%)\n2 (8.7%)\n5 (20%)\n4 (27%)\n6 (30%)\n4 (22%)\n3 (27%)\n4 (29%)\n2 (33%)\n2 (18%)\n2 (33%)\n2 (20%)\n1 (14%)\n4 (57%)\n1 (12%)\n1 (20%)\n0 (0%)\n1 (20%)\n0 (0%)\n1 (50%)\n2 (22%)\n0 (0%)\n3 (100%)\n1 (25%)\n0 (0%)\n1 (50%)\n1 (50%)\n1 (33%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (50%)\n1 (20%)\n0 (0%)\n2 (29%)\n0 (0%)\n    Blurred Vision\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (7.1%)\n4 (17%)\n0 (0%)\n2 (6.7%)\n0 (0%)\n1 (2.0%)\n2 (3.2%)\n0 (0%)\n3 (5.7%)\n0 (0%)\n2 (5.7%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (5.6%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (20%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n    Vomiting\n0 (0%)\n0 (0%)\n1 (14%)\n0 (0%)\n0 (0%)\n1 (7.1%)\n3 (13%)\n3 (10%)\n3 (10%)\n3 (6.5%)\n4 (8.0%)\n9 (15%)\n2 (5.0%)\n4 (7.5%)\n3 (11%)\n4 (11%)\n4 (17%)\n2 (8.7%)\n4 (16%)\n0 (0%)\n4 (20%)\n1 (5.6%)\n0 (0%)\n2 (14%)\n0 (0%)\n2 (18%)\n1 (17%)\n1 (10%)\n2 (29%)\n0 (0%)\n2 (25%)\n0 (0%)\n1 (14%)\n0 (0%)\n0 (0%)\n0 (0%)\n2 (22%)\n0 (0%)\n1 (33%)\n1 (25%)\n1 (100%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (25%)\n2 (33%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (20%)\n0 (0%)\n1 (14%)\n1 (50%)\n    Wheezing\n1 (50%)\n0 (0%)\n1 (14%)\n1 (11%)\n1 (14%)\n6 (43%)\n10 (43%)\n8 (28%)\n6 (20%)\n12 (26%)\n11 (22%)\n18 (29%)\n13 (32%)\n21 (40%)\n5 (19%)\n12 (34%)\n8 (33%)\n9 (39%)\n6 (24%)\n4 (27%)\n5 (25%)\n7 (39%)\n2 (18%)\n4 (29%)\n3 (50%)\n3 (27%)\n2 (33%)\n1 (10%)\n4 (57%)\n4 (57%)\n4 (50%)\n1 (20%)\n2 (29%)\n1 (20%)\n3 (75%)\n0 (0%)\n1 (11%)\n1 (50%)\n2 (67%)\n2 (50%)\n0 (0%)\n2 (100%)\n1 (50%)\n1 (33%)\n0 (0%)\n4 (67%)\n1 (50%)\n0 (0%)\n0 (0%)\n1 (50%)\n1 (50%)\n0 (0%)\n1 (50%)\n1 (20%)\n1 (100%)\n1 (14%)\n0 (0%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nSummary Tables for Nausea\n\nsummary (flu$Nausea) #Quick and basic overview \n\n No Yes \n475 255 \n\nnaus<- flu %>% tbl_summary(Nausea) #Breaking things down a bit more\nnaus\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      No, N = 4751\n      Yes, N = 2551\n    \n  \n  \n    Swollen Lymph Nodes\n200 (42%)\n112 (44%)\n    Chest Congestion\n246 (52%)\n161 (63%)\n    Chills/Sweats\n372 (78%)\n228 (89%)\n    Nasal Congestion\n355 (75%)\n208 (82%)\n    Cough\n429 (90%)\n226 (89%)\n    Sneeze\n242 (51%)\n149 (58%)\n    Fatigue\n424 (89%)\n242 (95%)\n    Subjective Fever\n309 (65%)\n191 (75%)\n    Headache\n387 (81%)\n228 (89%)\n    Weakness\n\n\n        None\n39 (8.2%)\n10 (3.9%)\n        Mild\n172 (36%)\n51 (20%)\n        Moderate\n210 (44%)\n128 (50%)\n        Severe\n54 (11%)\n66 (26%)\n    Weakness\n436 (92%)\n245 (96%)\n    Cough Severity\n\n\n        None\n30 (6.3%)\n17 (6.7%)\n        Mild\n99 (21%)\n55 (22%)\n        Moderate\n232 (49%)\n125 (49%)\n        Severe\n114 (24%)\n58 (23%)\n    CoughYN2\n445 (94%)\n238 (93%)\n    Myalgia\n\n\n        None\n63 (13%)\n16 (6.3%)\n        Mild\n159 (33%)\n54 (21%)\n        Moderate\n198 (42%)\n127 (50%)\n        Severe\n55 (12%)\n58 (23%)\n    Myalgia\n412 (87%)\n239 (94%)\n    Runny Nose\n336 (71%)\n183 (72%)\n    Abdominal Pain\n31 (6.5%)\n60 (24%)\n    Chest Pain\n135 (28%)\n98 (38%)\n    Diarrhea\n40 (8.4%)\n59 (23%)\n    Eye Pain\n71 (15%)\n42 (16%)\n    Sleeplessness\n260 (55%)\n155 (61%)\n    Itchy Eyes\n107 (23%)\n72 (28%)\n    Ear Pain\n96 (20%)\n66 (26%)\n    Loss of Hearing\n17 (3.6%)\n13 (5.1%)\n    Sore Throat\n395 (83%)\n216 (85%)\n    Breathlessness\n164 (35%)\n130 (51%)\n    Tooth Pain\n88 (19%)\n77 (30%)\n    Blurred Vision\n9 (1.9%)\n10 (3.9%)\n    Vomiting\n14 (2.9%)\n64 (25%)\n    Wheezing\n137 (29%)\n83 (33%)\n    BodyTemp\n98.50 (98.20, 99.30)\n98.60 (98.20, 99.30)\n  \n  \n  \n    \n      1 n (%); Median (IQR)\n    \n  \n\n\n\n\n\n\nHistogram/Density Plot for our Continuous Variable- Body Temperature\n\n#Basic histogram\ncv<- ggplot(flu, aes(x=BodyTemp)) +geom_histogram() #Basic histogram\n\n#Updated histogram\ncvup<- flu %>%\n  ggplot(aes(x=BodyTemp)) +     geom_histogram(binwidth=0.5, fill=\"#F08080\",color= \"#FAF0E6\", alpha=0.9) +\n  ggtitle(\"Body Temperature Histogram\") +\n  xlab(\"Body Temperature (in *F)\") +\n  ylab(\"Number of Individuals\")\n  \ncvup\n\n\n\ncvd<- flu %>% #Density plot\n  ggplot(aes(x=BodyTemp)) +   \n  geom_density(fill=\"#808000\",color= \"#FAF0E6\",\n  alpha=0.9) +\n  ggtitle(\"Body Temperature Histogram\") +\n  xlab(\"Body Temperature (in *F)\") +\n  ylab(\"Number of Individuals\")\n\ncvd \n\n\n\n\n\n\nPredictor Variables and Continuous Outcome of Interest\n\n#Subjective Fever and Body Temperature\npvoi0<-flu %>%\n  ggplot()+geom_boxplot(aes(\n                        x=SubjectiveFever,\n                        y=BodyTemp)) + labs(x=\"Subjective Fever\", y=\"Body Temperature (in *F)\", title=\"Subjective Fever and Body Temperature\")\n\npvoi0\n\n\n\n#Swollen Lymph Nodes and Body Temperature\npvoi1<-flu %>%\n  ggplot()+geom_boxplot(aes(\n                        x=SwollenLymphNodes,\n                        y=BodyTemp)) + labs(x=\"Swollen Lymph Nodes Present\", y=\"Body Temperature (in *F)\", title=\"Swollen Lymph Nodes and Body Temperature\")\n\npvoi1\n\n\n\n#Myalgia and Body Temperature \npvoi2<-flu %>%\n  ggplot()+geom_boxplot(aes(\n                        x=Myalgia,\n                        y=BodyTemp)) + labs(x=\"Severity of Myalgia\", y=\"Body Temperature (in *F)\", title=\"Myalgia and Body Temperature\")\n\npvoi2\n\n\n\n# Pharyngitis and Body Temperature\npvoi3<-flu %>%\n  ggplot()+geom_boxplot(aes(\n                        x=Pharyngitis,\n                        y=BodyTemp)) + labs(x=\"Pharyngitis\", y=\"Body Temperature (in *F)\", title=\"Pharyngitis and Body Temperature\")\n\npvoi3\n\n\n\n#Diarrhea and Body Temperature\npvoi4<-flu %>%\n  ggplot()+geom_boxplot(aes(\n                        x=Diarrhea,\n                        y=BodyTemp)) + labs(x=\"Diarrhea\", y=\"Body Temperature (in *F)\", title=\"Diarrhea and Body Temperature\")\n\npvoi4\n\n\n\n\nGiven the chosen predictor variables, it seems as those who experience the selected predictor variables (e.g., swollen lymph nodes) had slightly lower or similar mean body temperatures. Those with myalgia and subjective fever had higher body temperatures. Thus, for this exercise, I will select subjective temperature as a predictor variable for body temperature.\n\n\nPredictor Variables and Categorical Outcome of Interest\n\n#Myalgia and Nausea \npvoi5<-flu %>%\n  ggplot()+geom_count(aes(\n                        x=Nausea,\n                        y=Myalgia)) + labs(x=\"Nausea\", y=\"Myalgia\", title=\"Myalgia and Nausea\")\n\npvoi5\n\n\n\n# Diarrhea and Nausea\npvoi6<-flu %>%\n  ggplot()+geom_count(aes(\n                        x=Nausea,\n                        y=Diarrhea)) + labs(x=\"Nausea\", y=\"Diarrhea\", title=\"Diarrhea and Nausea\")\n\npvoi6\n\n\n\n# Swollen Lymph Nodes and Nausea\npvoi7<-flu %>%\n  ggplot()+geom_count(aes(\n                        x=Nausea,\n                        y=SwollenLymphNodes)) + labs(x=\"Nausea\", y=\"Swollen Lymph Nodes\", title=\"Swollen Lymph Nodes and Nausea\")\n\npvoi7\n\n\n\n# Cough Intensity and Nausea\npvoi8<-flu %>%\n  ggplot()+geom_count(aes(\n                        x=Nausea,\n                        y=CoughIntensity)) + labs(x=\"Nausea\", y=\"Cough Intensity\", title=\"Cough Intensity and Nausea\")\n\npvoi8\n\n\n\n#Subjective Fever and Nauesea\npvoi10<-flu %>%\n  ggplot()+geom_count(aes(\n                        x=Nausea,\n                        y=SubjectiveFever)) + labs(x=\"Nausea\", y=\"Subjective Fever\", title=\"Subjective Fever and Nausea\")\n\npvoi10\n\n\n\n\nGiven the chosen predictor variables, it seems as though there was no significant positive relationship with the selected predictor variables (e.g., swollen lymph nodes) and the categorical outcome of interest."
  },
  {
    "objectID": "fluanalysis/code/fitting.html",
    "href": "fluanalysis/code/fitting.html",
    "title": "Brian McKay’s Flu Analysis Data: Fitting",
    "section": "",
    "text": "Let’s Begin with some Fitting\nBut first let’s load some packages…\n\nlibrary(gtsummary) #To create tables will include\nlibrary(tidyr) #Helps with data wrangling\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\nlibrary(here) #Setting paths\n\nhere() starts at C:/GitHub/MADA/kimberlyperez-MADA-portfolio"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html",
    "href": "fluanalysis/code/machinelearning.html",
    "title": "Flu Analysis: Machine Learning",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-7\n\nlibrary(here)\n\nhere() starts at C:/GitHub/MADA/kimberlyperez-MADA-portfolio\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.2.3\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\nWarning: package 'rpart.plot' was built under R version 4.2.3\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tibble       3.1.8\n✔ infer        1.0.4     ✔ tidyr        1.3.0\n✔ modeldata    1.1.0     ✔ tune         1.0.1\n✔ parsnip      1.0.3     ✔ workflows    1.1.2\n✔ purrr        1.0.1     ✔ workflowsets 1.0.0\n✔ recipes      1.0.4     ✔ yardstick    1.1.0\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ tidyr::expand()   masks Matrix::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ tidyr::pack()     masks Matrix::pack()\n✖ dials::prune()    masks rpart::prune()\n✖ recipes::step()   masks stats::step()\n✖ tidyr::unpack()   masks Matrix::unpack()\n✖ recipes::update() masks Matrix::update(), stats::update()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ readr   2.1.4     ✔ forcats 0.5.2\n✔ stringr 1.5.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ readr::spec()       masks yardstick::spec()\n✖ tidyr::unpack()     masks Matrix::unpack()\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n\n\n\n\nflu<-readRDS(here(\"fluanalysis\",\"processed_data\", \"SympAct_cleaned.rds\")) #Loading in the data\n\nglimpse(flu) #Looking at the Data \n\nRows: 730\nColumns: 32\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html",
    "href": "fluanalysis/code/modeleval.html",
    "title": "Brian McKay’s Flu Analysis Data: Model Evaluation",
    "section": "",
    "text": "Let’s Begin with Model Evaluation"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#but-first-lets-load-some-packages",
    "href": "fluanalysis/code/modeleval.html#but-first-lets-load-some-packages",
    "title": "Brian McKay’s Flu Analysis Data: Model Evaluation",
    "section": "But first, let’s load some packages…",
    "text": "But first, let’s load some packages…\n\nlibrary(dplyr) #Data wrangling \n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #Helps with data wrangling\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\nlibrary(here) #Setting paths\n\nhere() starts at C:/GitHub/MADA/kimberlyperez-MADA-portfolio\n\nlibrary(tidyverse) #Data transformation\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ggplot2) #Graphs/Visualization\nlibrary(tidymodels) #For modeling\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#create-recipe-with-all-symptoms",
    "href": "fluanalysis/code/modeleval.html#create-recipe-with-all-symptoms",
    "title": "Brian McKay’s Flu Analysis Data: Model Evaluation",
    "section": "Create recipe with all symptoms",
    "text": "Create recipe with all symptoms\nFollowing the same steps as above:\n\n#create recipe using all symptoms as predictors of body temp\nflu_recBTAS <- \n  recipe(BodyTemp ~ ., data = train_data_flu)\n\n#set model\nln_mod <- linear_reg() %>% \n  set_engine(\"glm\")\n\n#create work flow\nflu_wflowBTAS <-\n  workflow() %>% \n  add_model(ln_mod) %>% \n  add_recipe(flu_recBTAS)\n\n#create fitted model\nflu_fitBTAS <-\n  flu_wflowBTAS %>% \n  fit(data = train_data_flu)\n\n#check fitted model\nflu_fitBTAS %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)           97.8        0.347   282.    0      \n 2 SwollenLymphNodesYes  -0.124      0.105    -1.17  0.241  \n 3 ChestCongestionYes     0.0731     0.112     0.655 0.513  \n 4 ChillsSweatsYes        0.140      0.148     0.949 0.343  \n 5 NasalCongestionYes    -0.183      0.131    -1.39  0.164  \n 6 CoughYNYes             0.353      0.268     1.31  0.189  \n 7 SneezeYes             -0.297      0.110    -2.70  0.00706\n 8 FatigueYes             0.360      0.185     1.94  0.0528 \n 9 SubjectiveFeverYes     0.361      0.116     3.11  0.00196\n10 HeadacheYes            0.0332     0.142     0.233 0.816  \n# … with 28 more rows\n\n\n<<<<<<< Updated upstream"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#predictions-from-trained-model",
    "href": "fluanalysis/code/modeleval.html#predictions-from-trained-model",
    "title": "Brian McKay’s Flu Analysis Data: Model Evaluation",
    "section": "Predictions from trained model",
    "text": "Predictions from trained model\nWe can also make predictions using the flu_fitBTAS model and the test_data_flu.\n\n#create predictions\nflu_augBTAS <- augment(flu_fitBTAS, test_data_flu)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n#check RMSE as metric for model performance\nflu_augBTAS %>% \n  rmse(truth = BodyTemp, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.23\n\n\n<<<<<<< Updated upstream\nThe root mean square error has an estimate of 1.230, indicating this would not be a good model for the data.\nWe can also use the train_data_flu data to make predictions.\n======= The root mean square error has an estimate of 1.230, indicating this would not be a good model for the data.\nWe can also use the train_data_flu data to make predictions. >>>>>>> Stashed changes\n\n#predict from training data\nflu_augRN2 <- augment(flu_fitBTAS, train_data_flu)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n#generate RMSE for model performance\nflu_augRN2 %>% \n  rmse(truth = BodyTemp, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.08\n\n\n<<<<<<< Updated upstream\nThe RMSE is lower for the train data, but still not an ideal value."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#create-recipe-with-runny-nose",
    "href": "fluanalysis/code/modeleval.html#create-recipe-with-runny-nose",
    "title": "Brian McKay’s Flu Analysis Data: Model Evaluation",
    "section": "Create recipe with Runny Nose",
    "text": "Create recipe with Runny Nose\n======= The RMSE is lower for the train data, but still not an ideal value."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#create-recipe-with-runny-nose-1",
    "href": "fluanalysis/code/modeleval.html#create-recipe-with-runny-nose-1",
    "title": "Brian McKay’s Flu Analysis Data: Model Evaluation",
    "section": "Create recipe with Runny Nose",
    "text": "Create recipe with Runny Nose\n\n\n\n\n\n\n\nStashed changes Follow the same steps with RunnyNose as the predictor.\n\n\n\n\n\n\n\n\n#create recipe using RunnyNose as predictor of body temp\nflu_recBTRN <- \n  recipe(BodyTemp ~ RunnyNose, data = train_data_flu)\n\n#set model\nln_mod <- linear_reg() %>% \n  set_engine(\"glm\")\n\n#create work flow\nflu_wflowBTRN <-\n  workflow() %>% \n  add_model(ln_mod) %>% \n  add_recipe(flu_recBTRN)\n\n#create fitted model\nflu_fitBTRN <-\n  flu_wflowBTRN %>% \n  fit(data = train_data_flu)\n\n#check fitted model\nflu_fitBTRN %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    99.1      0.0931   1065.    0     \n2 RunnyNoseYes   -0.246    0.110      -2.24  0.0252\n\n\n<<<<<<< Updated upstream\nHere, the model predicts Body Temperature from Runny Nose. Having a runny nose appears to predict a lower body temperature by 0.246 degrees."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#predictions-from-trained-model-1",
    "href": "fluanalysis/code/modeleval.html#predictions-from-trained-model-1",
    "title": "Brian McKay’s Flu Analysis Data: Model Evaluation",
    "section": "Predictions from trained model",
    "text": "Predictions from trained model\n======= Here, the model predicts Body Temperature from Runny Nose. Having a runny nose appears to predict a lower body temperature by 0.246 degrees."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#predictions-from-trained-model-2",
    "href": "fluanalysis/code/modeleval.html#predictions-from-trained-model-2",
    "title": "Brian McKay’s Flu Analysis Data: Model Evaluation",
    "section": "Predictions from trained model",
    "text": "Predictions from trained model\n\n\n\n\n\n\n\nStashed changes\n\n\n\n\n\n\n\n\n#create predictions\nflu_augBTRN <- augment(flu_fitBTRN, test_data_flu)\n\n#check RMSE as metric for model performance\nflu_augBTRN %>% \n  rmse(truth = BodyTemp, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.30\n\n\n<<<<<<< Updated upstream\n======= >>>>>>> Stashed changes The RMSE is similar to the all symptoms model with an estimate of 1.299.\n\n#predict from training data\nflu_augRN3 <- augment(flu_fitBTRN, train_data_flu)\n\n#generate RMSE for model performance\nflu_augRN3 %>% \n  rmse(truth = BodyTemp, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.15\n\n\n<<<<<<< Updated upstream"
  },
  {
    "objectID": "fluanalysis/code/wrangling.html",
    "href": "fluanalysis/code/wrangling.html",
    "title": "Brian McKay’s Flu Analysis Data: Wrangling",
    "section": "",
    "text": "Let’s Begin with some Data Wrangling\nBut first let’s load some packages…\n\nlibrary(here)\n\nhere() starts at C:/GitHub/MADA/kimberlyperez-MADA-portfolio\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ stringr 1.5.0\n✔ tidyr   1.3.0     ✔ forcats 0.5.2\n✔ readr   2.1.4     \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nAnd Load the Data…\n\nfluog<-readRDS(here(\"fluanalysis\",\"raw_data\", \"SympAct_Any_Pos.Rda\")) #Loading in the data\n\nglimpse(fluog) #Looking at the Data \n\nRows: 735\nColumns: 63\n$ DxName1           <fct> \"Influenza like illness - Clinical Dx\", \"Acute tonsi…\n$ DxName2           <fct> NA, \"Influenza like illness - Clinical Dx\", \"Acute p…\n$ DxName3           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Fever, unspecified\"…\n$ DxName4           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Other fatigue\", NA,…\n$ DxName5           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Headache\", NA, NA, …\n$ Unique.Visit      <chr> \"340_17632125\", \"340_17794836\", \"342_17737773\", \"342…\n$ ActivityLevel     <int> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ ActivityLevelF    <fct> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n$ RapidFluA         <fct> Presumptive Negative For Influenza A, NA, Presumptiv…\n$ RapidFluB         <fct> Presumptive Negative For Influenza B, NA, Presumptiv…\n$ PCRFluA           <fct> NA, NA, NA, NA, NA, NA,  Influenza A Not Detected, N…\n$ PCRFluB           <fct> NA, NA, NA, NA, NA, NA,  Influenza B Not Detected, N…\n$ TransScore1       <dbl> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore1F      <fct> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore2       <dbl> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore2F      <fct> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore3       <dbl> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore3F      <fct> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore4       <dbl> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ TransScore4F      <fct> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ ImpactScore       <int> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2      <int> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3      <int> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreF      <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2F     <fct> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3F     <fct> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreFD     <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ TotalSymp1        <dbl> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp1F       <fct> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp2        <dbl> 8, 10, 17, 16, 11, 14, 10, 11, 13, 10, 14, 19, 13, 1…\n$ TotalSymp3        <dbl> 8, 9, 16, 15, 11, 14, 10, 10, 12, 9, 13, 18, 12, 16,…\n\n\n\n\nNow to the Wrangling\nRemoving Variables\n\nflu_1<- fluog %>%\n  select(-contains(c(\"Activity\",\"Dxname\", \"FluA\", \"FluB\", \"Score\", \"Total\", \"Unique.Visit\"))) %>%  #Removing variables\n  drop_na() #With the pipe function I will tack on the removal of NAs \n\nglimpse(flu_1) #Cleaned data\n\nRows: 730\nColumns: 32\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n\n\nSaving the Cleaned Data\n\nsaveRDS(flu_1, file=here(\"fluanalysis\",\"processed_data\", \"SympAct_cleaned.rds\")) #I will save this to my processed data folder, code is similar to that of loading code"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kimberly Perez’s Website and Data Analysis Portfolio",
    "section": "",
    "text": "Here is where you can get to know me and my ongoing research; as well as track my MADA 2023 journey.\n\nPlease use the Menu Bar above to navigate throughout my site.\nHave fun!"
  },
  {
    "objectID": "tidytuesday_exercise.html",
    "href": "tidytuesday_exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Loading Libraries\n\nlibrary(ggplot2) #Loading some libraries I may use for this exercise\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.3.0      ✔ stringr 1.5.0 \n✔ readr   2.1.4      ✔ forcats 0.5.2 \n✔ purrr   1.0.1      \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ggthemes)\nlibrary(dplyr)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(tibble)\n\n\n\n“Getting the Data” Manually\n\nage_gaps <-  readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv') #Here I manually read in the csv used for this weeks TidyTuesday\n\nRows: 1155 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): movie_name, director, actor_1_name, actor_2_name, character_1_gend...\ndbl  (5): release_year, age_difference, couple_number, actor_1_age, actor_2_age\ndate (2): actor_1_birthdate, actor_2_birthdate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(age_gaps)\n\nspc_tbl_ [1,155 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ movie_name        : chr [1:1155] \"Harold and Maude\" \"Venus\" \"The Quiet American\" \"The Big Lebowski\" ...\n $ release_year      : num [1:1155] 1971 2006 2002 1998 2010 ...\n $ director          : chr [1:1155] \"Hal Ashby\" \"Roger Michell\" \"Phillip Noyce\" \"Joel Coen\" ...\n $ age_difference    : num [1:1155] 52 50 49 45 43 42 40 39 38 38 ...\n $ couple_number     : num [1:1155] 1 1 1 1 1 1 1 1 1 1 ...\n $ actor_1_name      : chr [1:1155] \"Ruth Gordon\" \"Peter O'Toole\" \"Michael Caine\" \"David Huddleston\" ...\n $ actor_2_name      : chr [1:1155] \"Bud Cort\" \"Jodie Whittaker\" \"Do Thi Hai Yen\" \"Tara Reid\" ...\n $ character_1_gender: chr [1:1155] \"woman\" \"man\" \"man\" \"man\" ...\n $ character_2_gender: chr [1:1155] \"man\" \"woman\" \"woman\" \"woman\" ...\n $ actor_1_birthdate : Date[1:1155], format: \"1896-10-30\" \"1932-08-02\" ...\n $ actor_2_birthdate : Date[1:1155], format: \"1948-03-29\" \"1982-06-03\" ...\n $ actor_1_age       : num [1:1155] 75 74 69 68 81 59 62 69 57 77 ...\n $ actor_2_age       : num [1:1155] 23 24 20 23 38 17 22 30 19 39 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   movie_name = col_character(),\n  ..   release_year = col_double(),\n  ..   director = col_character(),\n  ..   age_difference = col_double(),\n  ..   couple_number = col_double(),\n  ..   actor_1_name = col_character(),\n  ..   actor_2_name = col_character(),\n  ..   character_1_gender = col_character(),\n  ..   character_2_gender = col_character(),\n  ..   actor_1_birthdate = col_date(format = \"\"),\n  ..   actor_2_birthdate = col_date(format = \"\"),\n  ..   actor_1_age = col_double(),\n  ..   actor_2_age = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\nglimpse(age_gaps)#Gives me a snapshot of the columns in the df\n\nRows: 1,155\nColumns: 13\n$ movie_name         <chr> \"Harold and Maude\", \"Venus\", \"The Quiet American\", …\n$ release_year       <dbl> 1971, 2006, 2002, 1998, 2010, 1992, 2009, 1999, 199…\n$ director           <chr> \"Hal Ashby\", \"Roger Michell\", \"Phillip Noyce\", \"Joe…\n$ age_difference     <dbl> 52, 50, 49, 45, 43, 42, 40, 39, 38, 38, 36, 36, 35,…\n$ couple_number      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ actor_1_name       <chr> \"Ruth Gordon\", \"Peter O'Toole\", \"Michael Caine\", \"D…\n$ actor_2_name       <chr> \"Bud Cort\", \"Jodie Whittaker\", \"Do Thi Hai Yen\", \"T…\n$ character_1_gender <chr> \"woman\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", …\n$ character_2_gender <chr> \"man\", \"woman\", \"woman\", \"woman\", \"man\", \"woman\", \"…\n$ actor_1_birthdate  <date> 1896-10-30, 1932-08-02, 1933-03-14, 1930-09-17, 19…\n$ actor_2_birthdate  <date> 1948-03-29, 1982-06-03, 1982-10-01, 1975-11-08, 19…\n$ actor_1_age        <dbl> 75, 74, 69, 68, 81, 59, 62, 69, 57, 77, 59, 56, 65,…\n$ actor_2_age        <dbl> 23, 24, 20, 23, 38, 17, 22, 30, 19, 39, 23, 20, 30,…\n\n\n\n\nData Wrangling\nFrom the glimpse function, we can see that we have a lot of data- 13 columns and 1,155 rows. To parse this dataset down, I will first perform some data wrangling where I will remove unneeded columns.\nGiven the theme of this weeks Tidy Tuesday, I am interested in exploring trends in actor age difference throughout the years from movies released in the 60s and 70s versus the 2018-2022. I am also interested in comparing the age difference of actors that stared in my favorite director’s movies (e.g., Wes Anderson and Alfred Hitchcock).\n\nage_gaps1<-age_gaps[-c(3,5:13)] #Removing columns I do not need for my specific data visualization [Age Difference in lead actors from 1960-1980 vs. 2018-2022]\n\nage_gaps_2_yr<- age_gaps1 %>% filter(   #Selecting the years I want to keep in my dataset \n  release_year %in% c(\"1960\", \"1961\", \"1962\", \"1963\", \"1964\", \"1965\", \"1966\", \"1967\", \"1968\", \"1969\", \"1970\",\"1971\",\"1972\",\"1973\",\"1974\", \"1975\",\"1976\",\"1977\",\"1978\",\"1979\",\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"))\n\n\n\nData Visualization\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n#Utilizing Plotly for interaction: Age Difference of Lead Actors in movies by year between 1960-1979 and post Me too Movement 2018-2022\ngaps <- plot_ly(\n  type=\"scatter\", \n  mode=\"markers\",\n  age_gaps_2_yr, \n  x=~release_year, \n  y=~age_difference,\n  textposition= \"auto\",\n  hoverinfo= \"text\",\n  hovertext= paste(\"Movie Name :\", age_gaps_2_yr$movie_name),\n  yaxis= list(title='Lead Actors Age Difference')) %>%\n  layout(title = \"Age Difference of Lead Actors (Male/Female) in Movies from 1960-1970 and 2018-2022\", xaxis=list(title= 'Movie Release Year'), yaxis= list(title='Lead Actors Age Difference'))\n\ngaps\n\n\n\n\n\nThe largest age difference in actors occurred in the 1970 in the movie Harold and Maude.The age difference for actors looks to be similar in the years visualized for this exercise.\n\n\nMore Data Visualization by director\n\nage_gaps3dir<-age_gaps[-c(5:13)] #Here I will remove columns I do not need\n\ndir<-age_gaps3dir %>% filter(   #Selecting the directors I want to keep in my dataset Hitchcock and Anderson are my two favorite! \n  director %in% c( \"Wes Anderson\", \"Alfred Hitchcock\"))\n\ndad<- ggplot(dir, aes(x = release_year, y = age_difference)) +\n    geom_point(aes(color = factor(director)))\n\ndad + labs( x= \"Movie Release Year\",\n    y= \"Actor Age Difference\",\n    color= \"Director\",\n    title= \"Actor Age Difference in Alfred Hitchcock and Wes Anderson Films\")\n\n\n\n\nFrom the graph, it looks like Alfred Hitchcock had more actors with larger age differences than Wes Anderson."
  },
  {
    "objectID": "visualization_exercise.html",
    "href": "visualization_exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "The Data\nThe graph I attempted to reproduce below was retrieved from a FiveThirtyEight article “The National Parks Have Never Been More Popular”, by Andrew Flowers, that visualizes the rise in popularity of the US’s national parks throughout the years. The graph was created from annual visitor counts that date back to 1904. Based on these visitor counts, Flowers then ranked the national parks (e.g., park with most visitor count ranked highest). The National Park Services (NPS) have several detailed data sets that can be found here. The data set I utilized for this visualization exercise can be found on the aforementioned NPS page under the “Annual Visitation and Record Year by Park (1904-Last Calendar Year)”. You will be prompted to a page with three drop down menus. For”Region(s)” check “(Select All)”. Next, for “Park(s)” check “(Select All)”. Finally, for “Park Type”, scroll and check “National Park”. This will then return the data needed to replicate the graph below.\n\n\n\nLoading R Libraries\n\nlibrary(readr)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ dplyr   1.0.10\n✔ tibble  3.1.8      ✔ stringr 1.5.0 \n✔ tidyr   1.3.0      ✔ forcats 0.5.2 \n✔ purrr   1.0.1      \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(fivethirtyeight)\n\nSome larger datasets need to be installed separately, like senators and\nhouse_district_forecast. To install these, we recommend you install the\nfivethirtyeightdata package by running:\ninstall.packages('fivethirtyeightdata', repos =\n'https://fivethirtyeightdata.github.io/drat/', type = 'source')\n\nlibrary(ggthemes)\nlibrary(dplyr)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(tibble)\n\n\n\nData Loading, Exploring, and Cleaning\n\norig_nps<-read_csv(\"data/NPS Visitation Data.csv\")\n\nNew names:\nRows: 67 Columns: 122\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): ...1, ...2, ...3 num (118): ...4, ...5, ...7, ...8, ...9, ...10, ...11,\n...12, ...13, ...14, ... lgl (1): ...6\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...4`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n• `` -> `...9`\n• `` -> `...10`\n• `` -> `...11`\n• `` -> `...12`\n• `` -> `...13`\n• `` -> `...14`\n• `` -> `...15`\n• `` -> `...16`\n• `` -> `...17`\n• `` -> `...18`\n• `` -> `...19`\n• `` -> `...20`\n• `` -> `...21`\n• `` -> `...22`\n• `` -> `...23`\n• `` -> `...24`\n• `` -> `...25`\n• `` -> `...26`\n• `` -> `...27`\n• `` -> `...28`\n• `` -> `...29`\n• `` -> `...30`\n• `` -> `...31`\n• `` -> `...32`\n• `` -> `...33`\n• `` -> `...34`\n• `` -> `...35`\n• `` -> `...36`\n• `` -> `...37`\n• `` -> `...38`\n• `` -> `...39`\n• `` -> `...40`\n• `` -> `...41`\n• `` -> `...42`\n• `` -> `...43`\n• `` -> `...44`\n• `` -> `...45`\n• `` -> `...46`\n• `` -> `...47`\n• `` -> `...48`\n• `` -> `...49`\n• `` -> `...50`\n• `` -> `...51`\n• `` -> `...52`\n• `` -> `...53`\n• `` -> `...54`\n• `` -> `...55`\n• `` -> `...56`\n• `` -> `...57`\n• `` -> `...58`\n• `` -> `...59`\n• `` -> `...60`\n• `` -> `...61`\n• `` -> `...62`\n• `` -> `...63`\n• `` -> `...64`\n• `` -> `...65`\n• `` -> `...66`\n• `` -> `...67`\n• `` -> `...68`\n• `` -> `...69`\n• `` -> `...70`\n• `` -> `...71`\n• `` -> `...72`\n• `` -> `...73`\n• `` -> `...74`\n• `` -> `...75`\n• `` -> `...76`\n• `` -> `...77`\n• `` -> `...78`\n• `` -> `...79`\n• `` -> `...80`\n• `` -> `...81`\n• `` -> `...82`\n• `` -> `...83`\n• `` -> `...84`\n• `` -> `...85`\n• `` -> `...86`\n• `` -> `...87`\n• `` -> `...88`\n• `` -> `...89`\n• `` -> `...90`\n• `` -> `...91`\n• `` -> `...92`\n• `` -> `...93`\n• `` -> `...94`\n• `` -> `...95`\n• `` -> `...96`\n• `` -> `...97`\n• `` -> `...98`\n• `` -> `...99`\n• `` -> `...100`\n• `` -> `...101`\n• `` -> `...102`\n• `` -> `...103`\n• `` -> `...104`\n• `` -> `...105`\n• `` -> `...106`\n• `` -> `...107`\n• `` -> `...108`\n• `` -> `...109`\n• `` -> `...110`\n• `` -> `...111`\n• `` -> `...112`\n• `` -> `...113`\n• `` -> `...114`\n• `` -> `...115`\n• `` -> `...116`\n• `` -> `...117`\n• `` -> `...118`\n• `` -> `...119`\n• `` -> `...120`\n• `` -> `...121`\n• `` -> `...122`\n\nstr(orig_nps) #Exploring the NPS data a bit with these commands\n\nspc_tbl_ [67 × 122] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ...1  : chr [1:67] \"Annual Visitation and Record Year by Park (1904 - Last Calendar Year)\" NA \"Region\" \"Alaska Region\" ...\n $ ...2  : chr [1:67] NA NA \"Park Name\" \"Denali NP & PRES\" ...\n $ ...3  : chr [1:67] NA NA \"Park Type\" \"National Park\" ...\n $ ...4  : num [1:67] NA NA 1904 NA NA ...\n $ ...5  : num [1:67] NA NA 1905 NA NA ...\n $ ...6  : logi [1:67] NA NA NA NA NA NA ...\n $ ...7  : num [1:67] NA NA 1906 NA NA ...\n $ ...8  : num [1:67] NA NA 1907 NA NA ...\n $ ...9  : num [1:67] NA NA 1908 NA NA ...\n $ ...10 : num [1:67] NA NA 1909 NA NA ...\n $ ...11 : num [1:67] NA NA 1910 NA NA NA NA NA NA NA ...\n $ ...12 : num [1:67] NA NA 1911 NA NA ...\n $ ...13 : num [1:67] NA NA 1912 NA NA ...\n $ ...14 : num [1:67] NA NA 1913 NA NA ...\n $ ...15 : num [1:67] NA NA 1914 NA NA ...\n $ ...16 : num [1:67] NA NA 1915 NA NA ...\n $ ...17 : num [1:67] NA NA 1916 NA NA ...\n $ ...18 : num [1:67] NA NA 1917 NA NA ...\n $ ...19 : num [1:67] NA NA 1918 NA NA ...\n $ ...20 : num [1:67] NA NA 1919 NA NA ...\n $ ...21 : num [1:67] NA NA 1920 NA NA NA NA NA NA NA ...\n $ ...22 : num [1:67] NA NA 1921 NA NA ...\n $ ...23 : num [1:67] NA NA 1922 7 NA ...\n $ ...24 : num [1:67] NA NA 1923 34 NA ...\n $ ...25 : num [1:67] NA NA 1924 62 NA ...\n $ ...26 : num [1:67] NA NA 1925 206 NA ...\n $ ...27 : num [1:67] NA NA 1926 533 NA ...\n $ ...28 : num [1:67] NA NA 1927 651 NA ...\n $ ...29 : num [1:67] NA NA 1928 802 NA ...\n $ ...30 : num [1:67] NA NA 1929 1038 NA ...\n $ ...31 : num [1:67] NA NA 1930 951 NA NA NA NA NA NA ...\n $ ...32 : num [1:67] NA NA 1931 771 NA ...\n $ ...33 : num [1:67] NA NA 1932 357 NA ...\n $ ...34 : num [1:67] NA NA 1933 386 NA ...\n $ ...35 : num [1:67] NA NA 1934 628 NA ...\n $ ...36 : num [1:67] NA NA 1935 877 NA ...\n $ ...37 : num [1:67] NA NA 1936 1073 NA ...\n $ ...38 : num [1:67] NA NA 1937 1378 NA ...\n $ ...39 : num [1:67] NA NA 1938 1487 NA ...\n $ ...40 : num [1:67] NA NA 1939 2262 NA ...\n $ ...41 : num [1:67] NA NA 1940 1201 NA ...\n $ ...42 : num [1:67] NA NA 1941 1688 NA ...\n $ ...43 : num [1:67] NA NA 1942 5 NA ...\n $ ...44 : num [1:67] NA NA 1943 12 NA ...\n $ ...45 : num [1:67] NA NA 1944 0 NA ...\n $ ...46 : num [1:67] NA NA 1945 19 NA ...\n $ ...47 : num [1:67] NA NA 1946 1134 NA ...\n $ ...48 : num [1:67] NA NA 1947 3466 NA ...\n $ ...49 : num [1:67] NA NA 1948 4512 NA ...\n $ ...50 : num [1:67] NA NA 1949 4831 NA ...\n $ ...51 : num [1:67] NA NA 1950 6672 NA ...\n $ ...52 : num [1:67] NA NA 1951 7807 NA ...\n $ ...53 : num [1:67] NA NA 1952 7310 NA ...\n $ ...54 : num [1:67] NA NA 1953 6839 NA ...\n $ ...55 : num [1:67] NA NA 1954 5000 NA ...\n $ ...56 : num [1:67] NA NA 1955 3400 NA ...\n $ ...57 : num [1:67] NA NA 1956 5200 NA ...\n $ ...58 : num [1:67] NA NA 1957 10700 NA ...\n $ ...59 : num [1:67] NA NA 1958 25900 NA ...\n $ ...60 : num [1:67] NA NA 1959 25800 NA ...\n $ ...61 : num [1:67] NA NA 1960 22500 NA 900 600 NA NA NA ...\n $ ...62 : num [1:67] NA NA 1961 18300 NA ...\n $ ...63 : num [1:67] NA NA 1962 16600 NA ...\n $ ...64 : num [1:67] NA NA 1963 18400 NA ...\n $ ...65 : num [1:67] NA NA 1964 19200 NA ...\n $ ...66 : num [1:67] NA NA 1965 21400 NA ...\n $ ...67 : num [1:67] NA NA 1966 31300 NA ...\n $ ...68 : num [1:67] NA NA 1967 39800 NA ...\n $ ...69 : num [1:67] NA NA 1968 33300 NA ...\n $ ...70 : num [1:67] NA NA 1969 45400 NA ...\n $ ...71 : num [1:67] NA NA 1970 46000 NA 29700 11800 NA NA NA ...\n $ ...72 : num [1:67] NA NA 1971 44500 NA ...\n $ ...73 : num [1:67] NA NA 1972 88625 NA ...\n $ ...74 : num [1:67] NA NA 1973 137300 NA ...\n $ ...75 : num [1:67] NA NA 1974 161400 NA ...\n $ ...76 : num [1:67] NA NA 1975 160600 NA ...\n $ ...77 : num [1:67] NA NA 1976 157600 NA ...\n $ ...78 : num [1:67] NA NA 1977 183200 NA ...\n $ ...79 : num [1:67] NA NA 1978 223000 NA ...\n $ ...80 : num [1:67] NA NA 1979 251105 NA ...\n $ ...81 : num [1:67] NA NA 1980 216361 NA ...\n $ ...82 : num [1:67] NA NA 1981 256593 NA ...\n $ ...83 : num [1:67] NA NA 1982 321868 1381 ...\n $ ...84 : num [1:67] NA NA 1983 346082 2138 ...\n $ ...85 : num [1:67] NA NA 1984 395099 2440 ...\n $ ...86 : num [1:67] NA NA 1985 436545 1381 ...\n $ ...87 : num [1:67] NA NA 1986 529749 2801 ...\n $ ...88 : num [1:67] NA NA 1987 575013 1060 ...\n $ ...89 : num [1:67] NA NA 1988 592431 1258 ...\n $ ...90 : num [1:67] NA NA 1989 543640 822 ...\n $ ...91 : num [1:67] NA NA 1990 546693 1010 ...\n $ ...92 : num [1:67] NA NA 1991 558870 1154 ...\n $ ...93 : num [1:67] NA NA 1992 503674 2116 ...\n $ ...94 : num [1:67] NA NA 1993 505565 2245 ...\n $ ...95 : num [1:67] NA NA 1994 490311 1726 ...\n $ ...96 : num [1:67] NA NA 1995 543309 7074 ...\n $ ...97 : num [1:67] NA NA 1996 341385 6448 ...\n $ ...98 : num [1:67] NA NA 1997 354278 6949 ...\n $ ...99 : num [1:67] NA NA 1998 372519 8266 ...\n  [list output truncated]\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ...1 = col_character(),\n  ..   ...2 = col_character(),\n  ..   ...3 = col_character(),\n  ..   ...4 = col_number(),\n  ..   ...5 = col_number(),\n  ..   ...6 = col_logical(),\n  ..   ...7 = col_number(),\n  ..   ...8 = col_number(),\n  ..   ...9 = col_number(),\n  ..   ...10 = col_number(),\n  ..   ...11 = col_number(),\n  ..   ...12 = col_number(),\n  ..   ...13 = col_number(),\n  ..   ...14 = col_number(),\n  ..   ...15 = col_number(),\n  ..   ...16 = col_number(),\n  ..   ...17 = col_number(),\n  ..   ...18 = col_number(),\n  ..   ...19 = col_number(),\n  ..   ...20 = col_number(),\n  ..   ...21 = col_number(),\n  ..   ...22 = col_number(),\n  ..   ...23 = col_number(),\n  ..   ...24 = col_number(),\n  ..   ...25 = col_number(),\n  ..   ...26 = col_number(),\n  ..   ...27 = col_number(),\n  ..   ...28 = col_number(),\n  ..   ...29 = col_number(),\n  ..   ...30 = col_number(),\n  ..   ...31 = col_number(),\n  ..   ...32 = col_number(),\n  ..   ...33 = col_number(),\n  ..   ...34 = col_number(),\n  ..   ...35 = col_number(),\n  ..   ...36 = col_number(),\n  ..   ...37 = col_number(),\n  ..   ...38 = col_number(),\n  ..   ...39 = col_number(),\n  ..   ...40 = col_number(),\n  ..   ...41 = col_number(),\n  ..   ...42 = col_number(),\n  ..   ...43 = col_number(),\n  ..   ...44 = col_number(),\n  ..   ...45 = col_number(),\n  ..   ...46 = col_number(),\n  ..   ...47 = col_number(),\n  ..   ...48 = col_number(),\n  ..   ...49 = col_number(),\n  ..   ...50 = col_number(),\n  ..   ...51 = col_number(),\n  ..   ...52 = col_number(),\n  ..   ...53 = col_number(),\n  ..   ...54 = col_number(),\n  ..   ...55 = col_number(),\n  ..   ...56 = col_number(),\n  ..   ...57 = col_number(),\n  ..   ...58 = col_number(),\n  ..   ...59 = col_number(),\n  ..   ...60 = col_number(),\n  ..   ...61 = col_number(),\n  ..   ...62 = col_number(),\n  ..   ...63 = col_number(),\n  ..   ...64 = col_number(),\n  ..   ...65 = col_number(),\n  ..   ...66 = col_number(),\n  ..   ...67 = col_number(),\n  ..   ...68 = col_number(),\n  ..   ...69 = col_number(),\n  ..   ...70 = col_number(),\n  ..   ...71 = col_number(),\n  ..   ...72 = col_number(),\n  ..   ...73 = col_number(),\n  ..   ...74 = col_number(),\n  ..   ...75 = col_number(),\n  ..   ...76 = col_number(),\n  ..   ...77 = col_number(),\n  ..   ...78 = col_number(),\n  ..   ...79 = col_number(),\n  ..   ...80 = col_number(),\n  ..   ...81 = col_number(),\n  ..   ...82 = col_number(),\n  ..   ...83 = col_number(),\n  ..   ...84 = col_number(),\n  ..   ...85 = col_number(),\n  ..   ...86 = col_number(),\n  ..   ...87 = col_number(),\n  ..   ...88 = col_number(),\n  ..   ...89 = col_number(),\n  ..   ...90 = col_number(),\n  ..   ...91 = col_number(),\n  ..   ...92 = col_number(),\n  ..   ...93 = col_number(),\n  ..   ...94 = col_number(),\n  ..   ...95 = col_number(),\n  ..   ...96 = col_number(),\n  ..   ...97 = col_number(),\n  ..   ...98 = col_number(),\n  ..   ...99 = col_number(),\n  ..   ...100 = col_number(),\n  ..   ...101 = col_number(),\n  ..   ...102 = col_number(),\n  ..   ...103 = col_number(),\n  ..   ...104 = col_number(),\n  ..   ...105 = col_number(),\n  ..   ...106 = col_number(),\n  ..   ...107 = col_number(),\n  ..   ...108 = col_number(),\n  ..   ...109 = col_number(),\n  ..   ...110 = col_number(),\n  ..   ...111 = col_number(),\n  ..   ...112 = col_number(),\n  ..   ...113 = col_number(),\n  ..   ...114 = col_number(),\n  ..   ...115 = col_number(),\n  ..   ...116 = col_number(),\n  ..   ...117 = col_number(),\n  ..   ...118 = col_number(),\n  ..   ...119 = col_number(),\n  ..   ...120 = col_number(),\n  ..   ...121 = col_number(),\n  ..   ...122 = col_number()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\nsummary(orig_nps)\n\n     ...1               ...2               ...3                ...4       \n Length:67          Length:67          Length:67          Min.   :   563  \n Class :character   Class :character   Class :character   1st Qu.:  1250  \n Mode  :character   Mode  :character   Mode  :character   Median :  1904  \n                                                          Mean   : 17513  \n                                                          3rd Qu.:  8314  \n                                                          Max.   :101000  \n                                                          NA's   :60      \n      ...5          ...6              ...7            ...8      \n Min.   :   928   Mode:logical   Min.   :  700   Min.   :  900  \n 1st Qu.:  1200   NA's:67        1st Qu.: 1564   1st Qu.: 1705  \n Median :  1905                  Median : 1853   Median : 2334  \n Mean   : 20408                  Mean   : 4059   Mean   : 4355  \n 3rd Qu.: 14313                  3rd Qu.: 3444   3rd Qu.: 3839  \n Max.   :109000                  Max.   :17182   Max.   :16414  \n NA's   :60                      NA's   :59      NA's   :59     \n      ...9           ...10           ...11            ...12       \n Min.   :   80   Min.   :  165   Min.   :   250   Min.   :   206  \n 1st Qu.: 1773   1st Qu.:  854   1st Qu.:  2034   1st Qu.:  2637  \n Median : 2826   Median : 3216   Median :  4194   Median :  4000  \n Mean   : 4964   Mean   : 6979   Mean   : 17533   Mean   : 17788  \n 3rd Qu.: 5275   3rd Qu.: 5968   3rd Qu.: 12214   3rd Qu.: 11418  \n Max.   :19542   Max.   :32545   Max.   :120000   Max.   :130000  \n NA's   :58      NA's   :58      NA's   :57       NA's   :56      \n     ...13            ...14            ...15            ...16       \n Min.   :   230   Min.   :   280   Min.   :   502   Min.   :   663  \n 1st Qu.:  2582   1st Qu.:  3290   1st Qu.:  3664   1st Qu.:  6440  \n Median :  5235   Median :  6253   Median :  7096   Median : 12818  \n Mean   : 18163   Mean   : 19847   Mean   : 19192   Mean   : 26310  \n 3rd Qu.:  9915   3rd Qu.: 13618   3rd Qu.: 15092   3rd Qu.: 33881  \n Max.   :135000   Max.   :135000   Max.   :125000   Max.   :115000  \n NA's   :56       NA's   :56       NA's   :56       NA's   :55      \n     ...17            ...18            ...19            ...20       \n Min.   :  1385   Min.   :  1917   Min.   :  1918   Min.   :  1814  \n 1st Qu.: 10335   1st Qu.: 11645   1st Qu.:  9086   1st Qu.:  3000  \n Median : 14100   Median : 18387   Median : 15496   Median : 25000  \n Mean   : 27209   Mean   : 34844   Mean   : 33461   Mean   : 43042  \n 3rd Qu.: 34005   3rd Qu.: 35400   3rd Qu.: 36000   3rd Qu.: 58362  \n Max.   :118740   Max.   :135000   Max.   :140000   Max.   :169492  \n NA's   :55       NA's   :54       NA's   :54       NA's   :50      \n     ...21            ...22            ...23            ...24       \n Min.   :  1920   Min.   :  1921   Min.   :     7   Min.   :    15  \n 1st Qu.:  8665   1st Qu.: 13036   1st Qu.:  9500   1st Qu.:  6431  \n Median : 30949   Median : 28617   Median : 31177   Median : 41328  \n Mean   : 51136   Mean   : 51361   Mean   : 50311   Mean   : 55210  \n 3rd Qu.: 67111   3rd Qu.: 68661   3rd Qu.: 76509   3rd Qu.: 92675  \n Max.   :240966   Max.   :273737   Max.   :219164   Max.   :218000  \n NA's   :49       NA's   :48       NA's   :47       NA's   :45      \n     ...25            ...26            ...27            ...28       \n Min.   :    17   Min.   :   206   Min.   :   533   Min.   :   651  \n 1st Qu.:  8686   1st Qu.: 13651   1st Qu.: 19545   1st Qu.: 24836  \n Median : 35020   Median : 50952   Median : 53173   Median : 61151  \n Mean   : 58453   Mean   : 77586   Mean   : 87095   Mean   : 99954  \n 3rd Qu.: 88826   3rd Qu.:118958   3rd Qu.:130503   3rd Qu.:152692  \n Max.   :224211   Max.   :265500   Max.   :274209   Max.   :490430  \n NA's   :44       NA's   :45       NA's   :45       NA's   :45      \n     ...29            ...30            ...31            ...32       \n Min.   :   802   Min.   :   500   Min.   :   400   Min.   :   405  \n 1st Qu.: 34096   1st Qu.: 26106   1st Qu.: 35982   1st Qu.: 51995  \n Median : 76820   Median : 76822   Median : 88000   Median : 85000  \n Mean   :109988   Mean   :108078   Mean   :109788   Mean   :117479  \n 3rd Qu.:159144   3rd Qu.:149554   3rd Qu.:157693   3rd Qu.:156964  \n Max.   :460619   Max.   :461257   Max.   :458566   Max.   :461855  \n NA's   :45       NA's   :42       NA's   :42       NA's   :42      \n     ...33            ...34            ...35            ...36       \n Min.   :   357   Min.   :   386   Min.   :   275   Min.   :   300  \n 1st Qu.: 20356   1st Qu.: 11615   1st Qu.: 19791   1st Qu.: 15879  \n Median : 57338   Median : 51925   Median : 71901   Median : 83321  \n Mean   :109593   Mean   :103797   Mean   :119617   Mean   :125076  \n 3rd Qu.:153134   3rd Qu.:163980   3rd Qu.:218391   3rd Qu.:206316  \n Max.   :498289   Max.   :375000   Max.   :420000   Max.   :500000  \n NA's   :41       NA's   :39       NA's   :37       NA's   :35      \n     ...37            ...38             ...39            ...40       \n Min.   :   400   Min.   :    706   Min.   :  1130   Min.   :  1500  \n 1st Qu.: 20111   1st Qu.:  21213   1st Qu.: 20100   1st Qu.: 18000  \n Median :124697   Median : 124365   Median :121301   Median :116516  \n Mean   :173314   Mean   : 192804   Mean   :188685   Mean   :191680  \n 3rd Qu.:258988   3rd Qu.: 223413   3rd Qu.:224445   3rd Qu.:226741  \n Max.   :694098   Max.   :1041204   Max.   :954967   Max.   :911612  \n NA's   :33       NA's   :32        NA's   :31       NA's   :30      \n     ...41            ...42             ...43            ...44       \n Min.   :  1141   Min.   :      0   Min.   :     0   Min.   :     0  \n 1st Qu.: 18348   1st Qu.:  15506   1st Qu.:  7855   1st Qu.:  4570  \n Median :111185   Median : 124563   Median : 48144   Median : 18971  \n Mean   :201245   Mean   : 217969   Mean   : 97481   Mean   : 52331  \n 3rd Qu.:274769   3rd Qu.: 274002   3rd Qu.:124809   3rd Qu.: 60651  \n Max.   :950807   Max.   :1310101   Max.   :728706   Max.   :394140  \n NA's   :29       NA's   :26        NA's   :26       NA's   :26      \n     ...45            ...46            ...47             ...48        \n Min.   :     0   Min.   :     0   Min.   :      0   Min.   :      0  \n 1st Qu.:  3759   1st Qu.:  6397   1st Qu.:  16426   1st Qu.:  19374  \n Median : 19519   Median : 38624   Median : 124763   Median : 162563  \n Mean   : 62445   Mean   :108193   Mean   : 222159   Mean   : 264001  \n 3rd Qu.: 55707   3rd Qu.:130091   3rd Qu.: 308593   3rd Qu.: 376973  \n Max.   :534586   Max.   :750690   Max.   :1157930   Max.   :1204017  \n NA's   :25       NA's   :25       NA's   :25        NA's   :25       \n     ...49             ...50             ...51             ...52        \n Min.   :   1948   Min.   :   1949   Min.   :   1950   Min.   :   1951  \n 1st Qu.:  26703   1st Qu.:  37842   1st Qu.:  31636   1st Qu.:  36043  \n Median : 169063   Median : 200555   Median : 189286   Median : 224801  \n Mean   : 281803   Mean   : 325711   Mean   : 328327   Mean   : 371395  \n 3rd Qu.: 386848   3rd Qu.: 404359   3rd Qu.: 425890   3rd Qu.: 497083  \n Max.   :1469749   Max.   :1539641   Max.   :1843620   Max.   :1945100  \n NA's   :25        NA's   :25        NA's   :24        NA's   :24       \n     ...53             ...54             ...55             ...56        \n Min.   :   1952   Min.   :   1953   Min.   :   1954   Min.   :   1955  \n 1st Qu.:  49458   1st Qu.:  58464   1st Qu.:  59350   1st Qu.:  69100  \n Median : 312677   Median : 332835   Median : 337900   Median : 342200  \n Mean   : 425016   Mean   : 437933   Mean   : 452945   Mean   : 467239  \n 3rd Qu.: 564989   3rd Qu.: 590949   3rd Qu.: 581000   3rd Qu.: 642950  \n Max.   :2322152   Max.   :2250772   Max.   :2526900   Max.   :2581500  \n NA's   :24        NA's   :24        NA's   :24        NA's   :24       \n     ...57             ...58             ...59             ...60        \n Min.   :    500   Min.   :    600   Min.   :    700   Min.   :   1100  \n 1st Qu.:  62000   1st Qu.:  49975   1st Qu.:  57425   1st Qu.:  70650  \n Median : 303800   Median : 328900   Median : 340500   Median : 360450  \n Mean   : 488572   Mean   : 497117   Mean   : 519619   Mean   : 539682  \n 3rd Qu.: 669800   3rd Qu.: 692250   3rd Qu.: 711525   3rd Qu.: 778475  \n Max.   :2885800   Max.   :2943700   Max.   :3168900   Max.   :3162300  \n NA's   :22        NA's   :21        NA's   :21        NA's   :21       \n     ...61             ...62             ...63             ...64        \n Min.   :    600   Min.   :    600   Min.   :    300   Min.   :    700  \n 1st Qu.:  71800   1st Qu.:  83750   1st Qu.:  93450   1st Qu.: 103525  \n Median : 397700   Median : 415600   Median : 399000   Median : 410800  \n Mean   : 621101   Mean   : 644369   Mean   : 742316   Mean   : 740547  \n 3rd Qu.: 871600   3rd Qu.: 801450   3rd Qu.:1005450   3rd Qu.: 966825  \n Max.   :4528600   Max.   :4762100   Max.   :5209800   Max.   :5258700  \n NA's   :20        NA's   :20        NA's   :20        NA's   :19       \n     ...65             ...66             ...67             ...68        \n Min.   :    500   Min.   :    800   Min.   :    300   Min.   :   1200  \n 1st Qu.: 102325   1st Qu.: 118000   1st Qu.: 117900   1st Qu.: 146600  \n Median : 432250   Median : 480500   Median : 513000   Median : 516300  \n Mean   : 759212   Mean   : 852191   Mean   : 936444   Mean   : 913177  \n 3rd Qu.: 940675   3rd Qu.:1091300   3rd Qu.:1143800   3rd Qu.:1282800  \n Max.   :5321100   Max.   :5954900   Max.   :6466100   Max.   :6710100  \n NA's   :19        NA's   :18        NA's   :18        NA's   :18       \n     ...69             ...70             ...71             ...72        \n Min.   :   1600   Min.   :   1969   Min.   :   1970   Min.   :   1971  \n 1st Qu.: 147000   1st Qu.: 162600   1st Qu.: 183225   1st Qu.: 193875  \n Median : 578300   Median : 550300   Median : 611750   Median : 542550  \n Mean   : 967624   Mean   : 975214   Mean   :1018211   Mean   : 907303  \n 3rd Qu.:1540200   3rd Qu.:1299700   3rd Qu.:1367225   3rd Qu.:1306500  \n Max.   :6667100   Max.   :6331100   Max.   :6778500   Max.   :7173000  \n NA's   :18        NA's   :18        NA's   :17        NA's   :15       \n     ...73             ...74             ...75             ...76        \n Min.   :   1972   Min.   :   1973   Min.   :   1974   Min.   :   1975  \n 1st Qu.: 168896   1st Qu.: 196850   1st Qu.: 162775   1st Qu.: 242925  \n Median : 546286   Median : 500750   Median : 470750   Median : 558150  \n Mean   :1000728   Mean   : 960740   Mean   : 906212   Mean   : 994583  \n 3rd Qu.:1391299   3rd Qu.:1350050   3rd Qu.:1213925   3rd Qu.:1307375  \n Max.   :8034753   Max.   :7586300   Max.   :7807800   Max.   :8541500  \n NA's   :14        NA's   :13        NA's   :13        NA's   :13       \n     ...77             ...78             ...79             ...80        \n Min.   :   1976   Min.   :   1977   Min.   :   1978   Min.   :   1979  \n 1st Qu.: 215300   1st Qu.: 246000   1st Qu.: 276200   1st Qu.: 246900  \n Median : 625600   Median : 622300   Median : 663331   Median : 585678  \n Mean   :1068945   Mean   :1093285   Mean   :1073324   Mean   : 939412  \n 3rd Qu.:1312300   3rd Qu.:1375800   3rd Qu.:1321844   3rd Qu.:1400204  \n Max.   :8991500   Max.   :9173600   Max.   :8695534   Max.   :8019788  \n NA's   :12        NA's   :12        NA's   :11        NA's   :11       \n     ...81             ...82             ...83             ...84        \n Min.   :   1980   Min.   :   1981   Min.   :   1381   Min.   :   1983  \n 1st Qu.: 262219   1st Qu.: 264326   1st Qu.: 172287   1st Qu.: 164926  \n Median : 567420   Median : 592454   Median : 566807   Median : 577439  \n Mean   : 962913   Mean   :1020821   Mean   : 941126   Mean   : 958910  \n 3rd Qu.:1234220   3rd Qu.:1247455   3rd Qu.:1030484   3rd Qu.:1160008  \n Max.   :8440953   Max.   :8312884   Max.   :8177869   Max.   :8435475  \n NA's   :11        NA's   :11        NA's   :6         NA's   :6        \n     ...85             ...86             ...87             ...88         \n Min.   :   1075   Min.   :   1305   Min.   :   1085   Min.   :     230  \n 1st Qu.: 166610   1st Qu.: 183348   1st Qu.: 185612   1st Qu.:  203216  \n Median : 539476   Median : 505791   Median : 586668   Median :  651606  \n Mean   : 924798   Mean   : 925230   Mean   : 990115   Mean   : 1041905  \n 3rd Qu.:1142727   3rd Qu.:1139202   3rd Qu.:1228194   3rd Qu.: 1233212  \n Max.   :8508390   Max.   :9319290   Max.   :9836306   Max.   :10209841  \n NA's   :5         NA's   :4         NA's   :4         NA's   :4         \n     ...89             ...90             ...91             ...92        \n Min.   :   1258   Min.   :    822   Min.   :   1010   Min.   :   1154  \n 1st Qu.: 217918   1st Qu.: 238006   1st Qu.: 240466   1st Qu.: 212755  \n Median : 675397   Median : 600045   Median : 611375   Median : 679034  \n Mean   :1049132   Mean   :1061917   Mean   :1018962   Mean   :1083886  \n 3rd Qu.:1231204   3rd Qu.:1302215   3rd Qu.:1293538   3rd Qu.:1438690  \n Max.   :8770781   Max.   :8333553   Max.   :8151769   Max.   :8654459  \n NA's   :4         NA's   :4         NA's   :4         NA's   :4        \n     ...93             ...94             ...95             ...96        \n Min.   :   1992   Min.   :   1993   Min.   :   1726   Min.   :      0  \n 1st Qu.: 219461   1st Qu.: 214598   1st Qu.: 211855   1st Qu.: 241461  \n Median : 688742   Median : 666054   Median : 685031   Median : 663794  \n Mean   :1108917   Mean   :1141519   Mean   :1157714   Mean   :1197706  \n 3rd Qu.:1467198   3rd Qu.:1421256   3rd Qu.:1573088   3rd Qu.:1605836  \n Max.   :8931690   Max.   :9283848   Max.   :8628174   Max.   :9080420  \n NA's   :4         NA's   :4         NA's   :4         NA's   :4        \n     ...97             ...98             ...99             ...100        \n Min.   :   1996   Min.   :   1997   Min.   :   1998   Min.   :    1999  \n 1st Qu.: 285684   1st Qu.: 306023   1st Qu.: 271858   1st Qu.:  288709  \n Median : 644502   Median : 627720   Median : 604556   Median :  635736  \n Mean   :1198161   Mean   :1211313   Mean   :1204959   Mean   : 1195782  \n 3rd Qu.:1535120   3rd Qu.:1548693   3rd Qu.:1474971   3rd Qu.: 1443662  \n Max.   :9265667   Max.   :9965075   Max.   :9989395   Max.   :10283598  \n NA's   :5         NA's   :4         NA's   :4         NA's   :4         \n     ...101             ...102            ...103            ...104       \n Min.   :    2000   Min.   :   2001   Min.   :   1938   Min.   :      0  \n 1st Qu.:  257790   1st Qu.: 269938   1st Qu.: 237364   1st Qu.: 241347  \n Median :  605192   Median : 541787   Median : 558503   Median : 570953  \n Mean   : 1167022   Mean   :1133359   Mean   :1125762   Mean   :1097179  \n 3rd Qu.: 1467108   3rd Qu.:1377130   3rd Qu.:1401990   3rd Qu.:1323676  \n Max.   :10175812   Max.   :9197697   Max.   :9316420   Max.   :9366845  \n NA's   :4          NA's   :4         NA's   :3         NA's   :3        \n     ...105            ...106            ...107            ...108       \n Min.   :   2004   Min.   :   2005   Min.   :   1239   Min.   :    847  \n 1st Qu.: 258122   1st Qu.: 268943   1st Qu.: 246691   1st Qu.: 268616  \n Median : 549708   Median : 594893   Median : 569464   Median : 548004  \n Mean   :1112941   Mean   :1115680   Mean   :1040673   Mean   :1068904  \n 3rd Qu.:1363063   3rd Qu.:1424896   3rd Qu.:1260680   3rd Qu.:1299272  \n Max.   :9167046   Max.   :9192477   Max.   :9289215   Max.   :9372253  \n NA's   :4         NA's   :4         NA's   :3         NA's   :3        \n     ...109            ...110            ...111            ...112       \n Min.   :   1565   Min.   :   1879   Min.   :   2010   Min.   :   2011  \n 1st Qu.: 259539   1st Qu.: 221411   1st Qu.: 271609   1st Qu.: 270732  \n Median : 547580   Median : 568652   Median : 568426   Median : 550900  \n Mean   :1043258   Mean   :1078816   Mean   :1110641   Mean   :1072016  \n 3rd Qu.:1219177   3rd Qu.:1220559   3rd Qu.:1290286   3rd Qu.:1310031  \n Max.   :9044010   Max.   :9491437   Max.   :9463538   Max.   :9008830  \n NA's   :3         NA's   :3         NA's   :3         NA's   :3        \n     ...113            ...114            ...115             ...116        \n Min.   :   2012   Min.   :   2013   Min.   :       0   Min.   :       0  \n 1st Qu.: 243314   1st Qu.: 236605   1st Qu.:  262790   1st Qu.:  282101  \n Median : 518568   Median : 526974   Median :  538970   Median :  596116  \n Mean   :1110429   Mean   :1080282   Mean   : 1155141   Mean   : 1254802  \n 3rd Qu.:1323217   3rd Qu.:1315336   3rd Qu.: 1427298   3rd Qu.: 1473670  \n Max.   :9685829   Max.   :9354695   Max.   :10099276   Max.   :10712674  \n NA's   :3         NA's   :3         NA's   :3          NA's   :3         \n     ...117             ...118             ...119             ...120        \n Min.   :    2016   Min.   :    2017   Min.   :    2018   Min.   :    2019  \n 1st Qu.:  320378   1st Qu.:  304206   1st Qu.:  291636   1st Qu.:  325694  \n Median :  630326   Median :  667870   Median :  650660   Median :  681872  \n Mean   : 1369082   Mean   : 1396772   Mean   : 1370565   Mean   : 1422075  \n 3rd Qu.: 1554654   3rd Qu.: 1544675   3rd Qu.: 1667333   3rd Qu.: 1680013  \n Max.   :11312786   Max.   :11338893   Max.   :11421200   Max.   :12547743  \n NA's   :3          NA's   :3          NA's   :3          NA's   :3         \n     ...121             ...122        \n Min.   :    2020   Min.   :    2021  \n 1st Qu.:  162119   1st Qu.:  292505  \n Median :  454968   Median :  707328  \n Mean   : 1061464   Mean   : 1441467  \n 3rd Qu.: 1265616   3rd Qu.: 1713756  \n Max.   :12095720   Max.   :14161548  \n NA's   :3          NA's   :3         \n\nclass(orig_nps)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nnames(orig_nps) #Exploring columns names, they look to be all numbers\n\n  [1] \"...1\"   \"...2\"   \"...3\"   \"...4\"   \"...5\"   \"...6\"   \"...7\"   \"...8\"  \n  [9] \"...9\"   \"...10\"  \"...11\"  \"...12\"  \"...13\"  \"...14\"  \"...15\"  \"...16\" \n [17] \"...17\"  \"...18\"  \"...19\"  \"...20\"  \"...21\"  \"...22\"  \"...23\"  \"...24\" \n [25] \"...25\"  \"...26\"  \"...27\"  \"...28\"  \"...29\"  \"...30\"  \"...31\"  \"...32\" \n [33] \"...33\"  \"...34\"  \"...35\"  \"...36\"  \"...37\"  \"...38\"  \"...39\"  \"...40\" \n [41] \"...41\"  \"...42\"  \"...43\"  \"...44\"  \"...45\"  \"...46\"  \"...47\"  \"...48\" \n [49] \"...49\"  \"...50\"  \"...51\"  \"...52\"  \"...53\"  \"...54\"  \"...55\"  \"...56\" \n [57] \"...57\"  \"...58\"  \"...59\"  \"...60\"  \"...61\"  \"...62\"  \"...63\"  \"...64\" \n [65] \"...65\"  \"...66\"  \"...67\"  \"...68\"  \"...69\"  \"...70\"  \"...71\"  \"...72\" \n [73] \"...73\"  \"...74\"  \"...75\"  \"...76\"  \"...77\"  \"...78\"  \"...79\"  \"...80\" \n [81] \"...81\"  \"...82\"  \"...83\"  \"...84\"  \"...85\"  \"...86\"  \"...87\"  \"...88\" \n [89] \"...89\"  \"...90\"  \"...91\"  \"...92\"  \"...93\"  \"...94\"  \"...95\"  \"...96\" \n [97] \"...97\"  \"...98\"  \"...99\"  \"...100\" \"...101\" \"...102\" \"...103\" \"...104\"\n[105] \"...105\" \"...106\" \"...107\" \"...108\" \"...109\" \"...110\" \"...111\" \"...112\"\n[113] \"...113\" \"...114\" \"...115\" \"...116\" \"...117\" \"...118\" \"...119\" \"...120\"\n[121] \"...121\" \"...122\"\n\nnps1<-orig_nps[-c(1,3,6, 118:122)] #Here I will remove the columns that I do not need by selecting the column number\nnps2<-nps1[-c(1,2,65),] #I am going to clean the data a bit more by removing the two rows at the top of the dataset\nprint(nps2) #Much more succinct\n\n# A tibble: 64 × 114\n   ...2   ...4  ...5  ...7  ...8  ...9 ...10 ...11 ...12 ...13 ...14 ...15 ...16\n   <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 Park…  1904  1905  1906  1907  1908  1909  1910  1911  1912  1913  1914  1915\n 2 Dena…    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n 3 Gate…    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n 4 Glac…    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n 5 Katm…    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n 6 Kena…    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n 7 Kobu…    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n 8 Lake…    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n 9 Wran…    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n10 Arch…    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n# … with 54 more rows, and 101 more variables: ...17 <dbl>, ...18 <dbl>,\n#   ...19 <dbl>, ...20 <dbl>, ...21 <dbl>, ...22 <dbl>, ...23 <dbl>,\n#   ...24 <dbl>, ...25 <dbl>, ...26 <dbl>, ...27 <dbl>, ...28 <dbl>,\n#   ...29 <dbl>, ...30 <dbl>, ...31 <dbl>, ...32 <dbl>, ...33 <dbl>,\n#   ...34 <dbl>, ...35 <dbl>, ...36 <dbl>, ...37 <dbl>, ...38 <dbl>,\n#   ...39 <dbl>, ...40 <dbl>, ...41 <dbl>, ...42 <dbl>, ...43 <dbl>,\n#   ...44 <dbl>, ...45 <dbl>, ...46 <dbl>, ...47 <dbl>, ...48 <dbl>, …\n\n\nWhile our dataset is cleaner and more succinct, there are no column or row names\n\nnps3<- nps2 %>% #Using first row of dataset for column names \n    row_to_names(row_number=1)\n\nnps4<- nps3[!is.na(nps3$`Park Name`),] #Removing NA from Park Name column\n\nnps5<- nps4 %>% #Converting dataset from wide to long \n  pivot_longer(\n    cols = c(-`Park Name`), \n    names_to = \"year\", \n    values_to = \"visitors\",\n    values_drop_na = TRUE)\n\nnps_clean<- nps5 %>% #Ranking the parks \n    group_by(year) %>%\n    mutate(Rank = order(order(visitors, decreasing=TRUE))) %>%\n    ungroup() %>%\n  rename(park_name = `Park Name`)\n\n\n\nBeginning Data Visualization\n\nlibrary(ggthemes)\n\nnps_clean$year<-as.numeric(as.character(nps_clean$year)) #Making year numeric\n\n#Creating df for each of the top parks to overlay on nps_g1\nGSM<- nps_clean [which (nps_clean$park_name==\"Great Smoky Mountains NP\"),]  \n\nGC<- nps_clean [which (nps_clean$park_name==\"Grand Canyon NP\"),] \n\nRMNP<- nps_clean [which (nps_clean$park_name==\"Rocky Mountain NP\"),] \n\nYNP<- nps_clean [which (nps_clean$park_name==\"Yosemite NP\"),]\n\nYSNP<- nps_clean [which (nps_clean$park_name==\"Yellowstone NP\"),] \n\nZNP<- nps_clean [which (nps_clean$park_name==\"Zion NP\"),] \n\nANP<- nps_clean [which (nps_clean$park_name==\"Acadia NP\"),] \n    \nHSNP<- nps_clean [which (nps_clean$park_name==\"Hot Springs NP\"),]\n\nDNP<- nps_clean [which (nps_clean$park_name==\"Denali NP & PRES\"),]\n\nCCNP<- nps_clean [which (nps_clean$park_name==\"Carlsbad Caverns NP\"),]\n\nGBNP<- nps_clean [which (nps_clean$park_name==\"Great Basin NP\"),]\n\n\nnps_g1<- nps_clean %>% ggplot() +geom_line( \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"grey\") +\n  theme_fivethirtyeight() +\n  theme(legend.position = \"none\") + \n  scale_y_reverse(breaks=seq(50,1,-25), limits=c(62,-1)) + #setting y axis\n  scale_x_continuous(breaks=seq(1925,2000,25),limits=c(1904,2030)) + #setting y axis \n  xlab(\"Year\") + \n  ylab(\"Rank\") +\n  labs(title= \"The most popular national parks\",\n       subtitle= \"National parks ranked by number of visitors in a given year\") + \n  geom_line(data=GSM, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"darkolivegreen\") +\n    annotate(\"text\", x = 2000, y =0, label = \"Great Smoky Mountains\", color = \"darkolivegreen\", fontface=2, size=3) +\n  geom_line(data=GC, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"deepskyblue4\") +\n    annotate(\"text\", x = 2020, y =0.7, label = \"Grand Canyon\", color = \"deepskyblue4\", fontface=2, size=3) + \n  geom_line(data=RMNP, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"cyan4\")+\n    annotate(\"text\", x = 2021, y =2, label = \"Rocky Mountain\", color = \"cyan4\", fontface=2, size= 3) +\n  geom_line(data=YNP, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"chartreuse4\") +\n  annotate(\"text\", x = 2020, y =3.1, label = \"Yosemite\", color = \"chartreuse4\", fontface=2, size= 3) +\n  geom_line(data=YSNP, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"orange2\") +\n  annotate(\"text\", x = 2019, y =4.1, label = \"Yellowstone\", color = \"orange2\", fontface=2, size= 3) +\n  geom_line(data=ZNP, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"tomato\") +\n  geom_line(data=ANP, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"gold1\") +\n  geom_line(data=HSNP, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"plum3\") +\n  geom_line(data=DNP, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"mediumpurple1\") +\n  geom_line(data=CCNP, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"lightskyblue2\") +\n  geom_line(data=GBNP, \n  aes(x = year, y = Rank, color = park_name, group = park_name), color=\"maroon2\")\n  \n\nnps_g1\n\n\n\n\nHere is an update on my data visualization! 3/10/2023 I think I bit off a bit more than I could chew with this graph. But, I am pretty proud of how far I got with it. To make things a little more cohesive, I overrode the color to grey. I plan on continuing work on it tonight with the hopes of adding the 11 parks in color. It is definitely a work in progress!"
  }
]